# 3장 인덱스 튜닝

## 3.1 테이블 액세스 최소화
- SQL 튜닝은 랜덤 I/O와의 전쟁이다.
- SQL 성능 향상을 위해 DBMS가 제공하는 많은 기능이 느린 랜덤 I/O를 극복하기 위해 개발됐고, 조인 메소드의 발전은 물론 많은 튜닝 기법도 랜덤 I/O 최소화에 맞춰져 있다.


### 3.1.1 테이블 랜덤 액세스

#### 인덱스 ROWID는 물리적 주소? 논리적 주소?
```
SELECT * FROM 고객 WHERE 지역 = '서울' ;

Execution Plan
----------------------------------------
0   SELECT STATEMENT Optimizer=ALL_ROWS
1 0  TABLE ACCESS BY INDEX ROWID OF '고객' (TABLE)
2 1   INDEX RANGE SCAN OF '고객_지역_IDX' (INDEX)
```
- SQL이 참조하는 컬럼을 인덱스가 모두 포함하는 경우가 아니라면, 인덱스를 스캔한 후에 반드시 테이블을 액세스한다. 위 실행계획에서 `TABLE ACCESS BY INDEX ROWID`라고 표시된 부분이 여기에 해당한다.
- 인덱스를 스캔하는 이유는, 검색 조건을 만족하는 소량의 데이터를 인덱스에서 빨리 찾고 거기서 테이블 레코드를 찾아가기 위한 주소값인 ROWID를 얻으려는 데 있다.
- 그렇다면 인덱스 ROWID는 물리적 주소일까, 논리적 주소일까? 인덱스 ROWID는 물리적 주소보다 논리적 주소에 가깝다. 물리적으로 직접 연결되지 않고 테이블 레코드를 찾아가기 위한 논리적 주소 정보를 담고 있기 때문이다.
- 데이터베이스 인덱스를 설명할 때 항상 도서 색인에 비유한다. 색인에 기록된 페이지 번호가 ROWID에 해당한다.
- 인덱스 ROWID를 포인터라고 생각하는 경우도 있다. 하지만 메모리 주소값을 담는 포인터는 메모리상 데이터를 찾아가는 데 있어 비용이 0에 가깝고, 사실상 물리적으로 직접 연결된 구조와 다름없다. 인덱스는 ROWID는 포인터가 아니다.
- 인덱스 ROWID는 논리적 주소다. 디스크 상에서 테이블 레코드를 찾아가기 위한 위치 정보를 담는다. 테이블 레코드과 물리적으로 직접 연결된 구조가 아니다.

#### 메인 메모리와 DB 비교
- 메인 메모리 DB(MMDB)는 데이터를 모두 메모리에 로드해 놓고 메모리를 통해서만 I/O를 수행하는 DB이다.
- 잘 튜닝된 OLTP성 데이터베이스 시스템이라면 버퍼캐시 히트율이 99% 이상이다. 디스크를 경유하지 않고 대부분 데이터를 메모리에서 읽는다는 뜻이다. 하지만 메인 메모리 DB만큼 빠르지는 않다. 특히 대량 데이터를 인덱스로 액세스할 때는 엄청난 차이가 난다.
- 벤더에 따라 내부 아키텍처가 모두 다르겠지만, 어떤 메인 메모리 DB의 경우 인스턴스를 기동하면 디스크에 저장된 데이터를 버퍼캐시로 로딩하고 이어서 인덱스를 생성한다. 이때 인덱스는 오라클처럼 디스크 상의 주소정보를 갖는게 아니라 메모리상의 주소정보, 즉 포인터(pointer)를 갖는다. 따라서 인덱스를 경유해 테이블을 액세스하는 비용이 오라클과 비교할 수 없을 정도로 낮다.
- 오라클은 테이블 블록이 수시로 버퍼캐시에서 밀려났다가 다시 캐싱되며, 그때마다 다른 공간에 캐싱되기 때문에 인덱스에서 포인터로 직접 연결할 수 없는 구조다. 메모리 주소 정보(포인터)가 아닌 디스크 주소 정보(DBA, Data Block Address)를 이용해 해시 알고리즘으로 버퍼 블록을 찾아간다.

#### I/O 메커니즘 복습
- DBA(데이터파일번호 + 블록번호)는 디스크 상에서 블록을 찾기 위한 주소 정보다.
- 매번 디스크에서 블록을 읽을 수는 없기에, I/O 성능을 높이려면 버퍼캐시를 활용해야 한다. 그래서 블록을 읽을 때는 디스크로 가기 전에 버퍼캐시부터 찾아본다. 읽고자 하는 DBA를 해시 함수에 입력해서 해시 체인을 찾고 거기서 버퍼 헤더를 찾는다.
- 캐시에 적재할 때와 읽을 때 같은 해시 함수를 사용하므로 버퍼 헤더는 항상 같은 해시 체인에 연결된다. 반면, 실제 데이터가 담긴 버퍼 블록은 매번 다른 위치에 캐싱되는데, 그 메모리 주소값을 버퍼 헤더가 가지고 있다.
- 정리하면, 해싱 알고리즘으로 버퍼 헤더를 찾고, 거기서 얻은 포인터로 버퍼 블록을 찾아간다.
- 인덱스로 테이블 블록을 액세스할 때는 리프 블록에서 얻은 ROWID를 분해해서 DBA 정보를 얻고, 테이블을 FULL SCAN 할 때는 익스텐트 맵을 통해 읽을 블록들의 DBA 정보를 얻는다.
- 인덱스 ROWID는 물리적 주소가 아니라 디스크 상에서 테이블 레코드를 찾아가기 위한 논리적인 주소 정보다. ROWID가 가리키는 테이블 블록을 버퍼 캐시에서 먼저 찾아보고, 못 찾을 때만 디스크에서 블록을 읽는다. 물론 버퍼캐시에 적재한 후에 읽는다.
- 설령 모든 데이터가 캐싱돼 있더라도 테이블 레코드를 찾기 위해 매번 DBA 해싱과 래치 획득 과정을 반복해야 한다. 동시 액세스가 심할 때는 캐시버퍼 체인 래치와 버퍼 Lock에 대한 경합까지 발생한다. 이처럼 인덱스 ROWID를 이용한 테이블 액세스는 고비용 구조다.

#### 인덱스 ROWID는 우편주소
- 디스크 DB(오라클, SQL Server 같은 일반 DBMS)가 사용하는 ROWID를 우편주소에, 메인 메모리 DB가 사용하는 포인터를 전화번호에 비유할 수 있다.
    - 전화통신은 물리적으로 연결된 통신망을 이용하므로 전화번호를 누르면 곧바로 상대방과 통화할 수 있다.
    - 하지만 우편통신은 봉투에 적힌 대로 우체부가 일일이 찾아다니는 구조이므로 전화와는 비교할 수 없이 느리다.


### 3.1.2 인덱스 클러스터링 팩터
- 클러스터링 팩터(Clustering Factor, 이하 'CF')는 '군집성 계수'로 번역할 수 있는 용어로서, 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 모여있는 정도를 의미한다. CF가 좋은 컬럼에 생성한 인덱스는 검색 효율이 매우 좋다.
    - 예를 들어 `거주지역 = '제주'`에 해당하는 고객 데이터가 물리적으로 근접해 있으면 흩어져 있을 때보다 데이터를 찾는 속도가 빠르다.

![그림3-4](https://github.com/user-attachments/assets/70dc9c51-13df-4112-9bd1-bc5c9a016089)
- 위 그림은 인덱스 클러스터링 팩터가 가장 좋은 상태를 도식화한 것으로서, 인덱스 레코드 정렬 순서와 테이블 레코드 정렬 순서가 100% 일치하는 것을 볼 수 있다.

![그림3-5](https://github.com/user-attachments/assets/0a4a5b58-35b6-49ab-af81-924e02fc0a19)
- 반면, 위 그림은 인덱스 클러스터링 팩터가 안 좋은 상태를 도식화한 것으로서, 인덱스 레코드 정렬 순서와 테이블 레코드 정렬 순서가 일치하지 않는다.

#### 인덱스 클러스터링 팩터 효과
- CF가 좋은 컬럼에 생성한 인덱스는 검색 효율이 좋다고 했는데, 이는 테이블 액세스량에 비해 블록 I/O가 적게 발생함을 의미한다.
- 그렇다면 인덱스 레코드마다 테이블 레코드를 건건이 블록 단위로 I/O 한다면, CF가 달라도 블록 I/O 발생량에 차이가 없어야 하지 않을까?
- 인덱스 ROWID로 테이블을 액세스할 때, 오라클은 래치 획득과 해시 체인 스캔 과정을 거쳐 어렵게 찾아간 테이블 블록에 대한 포인터(메모리 주소값)를 바로 해제하지 않고 일단 유지한다. 이를 `버퍼 Pinning`이라고 부른다.
- 이 상태에서 다음 인덱스 레코드를 읽었는데, 마침 **직전과 같은** 테이블 블록을 가리킨다. 그러면 래치 획득과 해시 체인 스캔 과정을 생략하고 바로 테이블 블록을 읽을 수 있다. 논리적인 블록 I/O 과정을 생략할 수 있는 것이다.

![그림3-6](https://github.com/user-attachments/assets/b9f3cddb-c843-4dcc-9b94-0b9e08ab4ae8)
- 위 그림은 CF가 좋은 인덱스를 사용할 때 테이블 액세스 횟수에 비해 블록 I/O가 적게 발생하는 이유를 잘 설명해준다. 굵은 실선이 실제 블록 I/O가 발생하는 경우다. 가는 점선은 논리적인 블록 I/O 없이 포인터로 바로 액세스하는 경우다.
- 만약 CF가 안 좋은 인덱스를 사용하면 테이블을 액세스하는 횟수만큼 고스란히 블록 I/O가 발생한다.


### 3.1.3 인덱스 손익분기점
- 인덱스 ROWID를 이용한 테이블 액세스는 생각보다 고비용 구조다. 읽어야 할 데이터가 일정량을 넘는 순간, 테이블 전체를 스캔하는 것보다 오히려 느려진다. Index Range Scan에 의한 테이블 액세스가 Table Full Scan보다 느려지는 지점을 흔히 `인덱스 손익분기점`이라고 부른다.
- Table Full Scan은 성능이 일정하다. 전체 1,000만 건 중 한 건을 조회하든, 10만 건을 조회하든, 1000만 건을 다 조회하든 차이가 거의 없다.
- 인덱스를 이용해 테이블을 액세스할 때는 전체 1,000만 건 중 몇 건을 추출하느냐에 따라 성능이 크게 달라진다. 당연히 추출 건수가 많을수록 느려진다. 테이블 랜덤 액세스 때문이다.
- 인덱스를 이용한 테이블 액세스가 Table Full Scan보다 더 느려지게 만드는 가장 핵심적인 두 가지 요인은 다음과 같다.
    - Table Full Scan은 시퀀셜 액세스인 반면, 인덱스 ROWID를 이용한 테이블 액세스는 랜덤 액세스 방식이다.
    - Table Full Scan은 Multiblock I/O인 반면, 인덱스 ROWID를 이용한 테이블 액세스는 Sigle Block I/O 방식이다.

![그림3-8](https://github.com/user-attachments/assets/abd0b7d2-7d42-4d9c-bdf8-c04682928492)
- 인덱스 손익분기점은 보통 5~20%의 낮은 수준에서 결정된다.
- CF에 따라서 인덱스 손익분기점이 크게 달라진다. 인덱스 CF가 나쁘면 같은 테이블 블록을 여러 번 반복 액세스하면서 논리적 I/O 횟수가 늘고, 물리적 I/O 횟수도 늘기 때문이다.
- CF가 나쁘면 손익분기점은 5% 미만에서 결정되며, 심할 때는(BCHR이 매우 안 좋을 때) 1% 미만으로 낮아진다. 반대로 CF가 아주 좋을 때(인위적으로 전체 데이터를 인덱스 컬럼 순으로 정렬해서 재입력 했을 때)는 손익분기점이 90% 수준까지 올라가기도 한다.

#### 인덱스 손익분기점과 버퍼캐시 히트율
- 일반적으로 말하는 5~20% 수준의 손익분기점은 10만 건 이내, 많아 봐야 100만 이내 테이블에나 적용되는 수치다. 1,000만 건 수준의 큰 테이블에서는 손익분기점이 더 낮아진다.
- 예를 들어, 10만 건 테이블에서 10%는 1만 건이다. 1만 건 정도면 버퍼캐시에서 데이터를 찾을 가능성이 어느 정도 있다. 그리고 인덱스 컬럼 기준으로 값이 테이블 레코드가 근처에 모여 있을 가능성이 있다. 따라서 인덱스를 스캔하면서 테이블을 액세스하다 보면 어느 순간부터 대부분 테이블 블록을 캐시에서 찾게 된다.
- 1,000만 건 테이블에서는 10%면 100만 건이다. 많은 트랜잭션이 버퍼캐시를 동시에 사용하는 운영 시스템에서 100만 건 데이터를 인덱스로 추출하면 최초 조회 시에는 시간이 많이 걸린다. 조회 건수가 늘어난 양에 비해 성능이 훨씬 더 느려지는 현상을 경험하게 된다. 조회 건수가 늘수록 데이터를 버퍼캐시에서 찾을 가능성이 작아지기 때문에 나타나는 현상이다.
- 버퍼캐시에 할당하는 메모리 크기가 점점 커지는 추세지만, 데이터베이스에 저장된 **전체** 테이블에 대해서 보통 수백만 개 블록을 캐싱하는 수준이다. 따라서 **특정** 테이블을 인덱스로 100만 건 이상 액세스한다면 캐시 히트율은 극히 낮을 수 밖에 없다.
- 1,000만 건 정도 테이블이면 인덱스 컬럼 기준으로 값이 같은 테이블 레코드가 근처에 모여 있을 가능성이 매우 작다. 인덱스를 스캔하면서 읽은 테이블 블록을 뒤에서 다시 읽을 가능성이 작기 때문에 거의 모든 데이터를 디스크에서 읽게 된다. 이런 상황이면 손익분기점 자체가 의미 없어진다.
- 1만 건만 넘어도 시퀀셜 액세스와 Multiblock I/O 방식, 즉 Table Full Scan 방식으로 읽는 게 빠를 수 있다.

#### 온라인 프로그램 튜닝 VS 배치 프로그램 튜닝
- 온라인 프로그램은 보통 소량 데이터를 읽고 갱신하므로 인덱스를 효과적으로 활용하는 것이 무엇보다 중요하다. 조인도 대부분 NL 방식을 사용한다. (NL 조인은 인덱스를 이용하는 조인 방식이다.) 인덱스를 이용해 소트 연산을 생략함으로써 부분범위 처리 방식으로 구현할 수 있다면, 온라인 환경에서 대량 데이터를 조회할 때도 아주 빠른 응답 속도를 낼 수 있다.
- 반면, 대량 데이터를 읽고 갱신하는 배치(Batch) 프로그램은 항상 전체범위 처리 기준으로 튜닝해야 한다. 즉, 처리대상 집합 중 일부를 빠르게 처리하는 것이 아니라 전체를 빠르게 처리하는 것을 목표로 삼아야 한다. 대량 데이터를 빠르게 처리하려면, 인덱스와 NL 조인보다 Full Scan과 해시 조인이 유리하다.

```
SELECT C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
FROM   고객 C, 고객변경이력 H
WHERE  C.실명확인번호 = :rmnno
AND    H.고객번호 = C.고객번호
AND    H.변경일시 = (SELECT MAX(변경일시)
                    FROM   고객변경이력 M
                    WHERE  고객번호 = C.고객번호
                    AND    변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
                    AND    변경일시 <  TRUNC(SYSDATE, 'MM'))
```
- 위 쿼리는 실명확인번호로 조회한 특정 고객의 최근 1년 이내 변경 이력 중 전월 말일 데이터를 출력한다.
- 실명확인번호 조건에 해당하는 데이터를 한 건이거나 소량이므로 인덱스와 NL 조인을 사용하는 위 방식이 효과적이다.

```
INSERT INTO 고객_임시
SELECT C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
FROM   고객 C, 고객변경이력 H
WHERE  C.고객구분코드 = 'A001'
AND    H.고객번호 = C.고객번호
AND    H.변경일시 = (SELECT MAX(변경일시)
                    FROM   고객변경이력 M
                    WHERE  고객번호 = C.고객번호
                    AND    변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
                    AND    변경일시 <  TRUNC(SYSDATE, 'MM'))
```
- 위 쿼리는 고객구분코드가 'A001'인 고객의 최근 1년 이내 변경 이력 중 전월 말일 데이터를 읽어 고객_임시 테이블에 입력한다.
- 전체 300만 명 중 고객구분코드를 만족하는 고객은 100만 명이다. 이럴 때 위와 같이 기존 실명확인번호 조건절을 고객구분코드 조건절로 바꿔서 직전과 같은 방식으로 수행하면 결코 빠른 성능을 낼 수 없다.

```
INSERT INTO 고객_임시
SELECT /*+ FULL(C) FULL(H) INDEX_FFS(M.고객변경이력)
           ORDERED NO_MERGE(M) USE_HASH(M) USE_HASH(H) */       
       C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
FROM   고객 C
     , (SELECT 고객번호, MAX(변경일시) 최종변경일시
        FROM   고객변경이력
        WHERE  변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
        AND    변경일시 <  TRUNC(SYSDATE, 'MM')
        GROUP BY 고객번호) M
    ,  고객변경이력 H
WHERE  C.고객구분코드 = 'A001'
AND    M.고객번호 = C.고객번호
AND    H.고객번호 = M.고객번호
AND    H.변경일시 = M.최종변경일시
```
- 쿼리를 위와 같이 변경하고 FULL SCAN과 해시 조인을 사용해야 효과적이다. 조건절에 해당하지 않는 고객 데이터, 1년을 초과한 이력 데이터까지 읽는 비효율이 있지만, 수행속도는 훨씬 빠르다.

```
INSERT INTO 고객_임시
SELECT 고객번호, 고객명, 전화번호, 주소, 상태코드, 변경일시
FROM (SELECT /*+ FULL(C) FULL(H) LEADING(C) USE_HASH(H) */    
       C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
       , RANK() OVER (PARTITION BY H.고객번호 ORDER BY H.변경일시 DESC) NO
      FROM   고객 C, 고객변경이력 H
      WHERE  C.고객구분코드 = 'A001'
      AND    H.변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
      AND    H.변경일시 <  TRUNC(SYSDATE, 'MM')
      AND    H.고객번호 = C.고객번호)
WHERE NO = 1
```
- 고객변경이력 테이블을 두 번 읽는 비효율을 없애려면, 위와 같이 윈도우 함수를 이용하면 된다.
- 대량 배치 프로그램에서는 인덱스보다 FULL SCAN이 효과적이지만, 초대용량 테이블을 FULL SCAN하면 상당히 오래 기다려야 하고 시스템에 주는 부담도 적지 않다. 따라서 배치 프로그램에서는 파티션 활용 전략이 매우 중요한 튜닝 요소이고, 병렬 처리까지 더할 수 있으면 더 좋다.
- 위 쿼리의 고객변경이력 테이블을 변경일시 기준으로 파티셔닝하면 변경일시 조건(최근 1년)에 해당하는 파티션만 골라서 FULL SCAN하므로 부담을 크게 줄일 수 있다.
- 파티션 테이블에도 인덱스를 사용할수 있지만, 월 단위로 파티션한 테이블에서 특정 월 또는 몇 개월 치 데이터를 조회할 때 인덱스는 좋은 선택이 아니다. 보름 또는 일주일 치 데이터를 조회하더라도 인덱스보다 FULL SCAN이 유리하며, 심지어 2~3일 데이터를 조회할 때도 FULL SCAN이 유리할수 있다. 테이블을 파티셔닝하는 이유는 결국 FULL SCAN을 빠르게 처리하기 위해서다.


### 3.1.4 인덱스 컬럼 추가
- 테이블 액세스 최소화를위해 가장 일반적으로 사용하는 튜닝 기법은 인덱스에 컬럼을 추가하는 것이다.
 
```
SELECT /*+ INDEX(EMP EMP_NO1) */ *
FROM   EMP
WHERE  DEPTNO = 30
AND    SAL >= 2000
```
- EMP 테이블에 현재 PK 이외에 `DEPTNO + JOB`순으로 구성한 EMP_X01 인덱스 하나만 있는 상태에서 위 SQL 쿼리를 수행하려고 한다.

![그림3-9](https://github.com/user-attachments/assets/59d1f365-44d6-4d71-b488-5fcf1694be9b)
- 위의 그림을 참고하면, 위 조건을 만족하는 사원이 단 한 명인데, 이를 찾기 위해 테이블을 여섯 번 액세스하였다.
- 인덱스 구성을 `DEPTNO + SAL`순으로 변경하면 좋겠지만, 실 운영 환경에서는 인덱스 구성을 변경하기가 절대 쉽지 않다.

```
SELECT * FROM EMP WHERE DEPTNO = 30 AND JOB = 'CLERK'
```
- 위 SQL과 같이 기존 인덱스를 사용하는 SQL이 있을 수 있기 때문이다.
- 결국 인덱스를 새로 만들어야겠지만 이런 식으로 인덱스를 추가하다 보면 테이블마다 인덱스가 수십 개씩 달려 배보다 배꼽이 더 커지게 된다. 인덱스 관리 비용이 증가함은 물론 DML 부하에 따른 트랜잭션 성능 저하가 생길 수 있다.

![그림3-10](https://github.com/user-attachments/assets/e89b0c09-1739-485f-98a7-ef98bcf95552)
- 이럴 때, 책의 그림(그림3-10)을 참고하면 기존 인덱스에 SAL 컬럼을 추가하는 것만으로 큰 효과를 얻을 수 있다.
- 인덱스 스캔량은 줄지 않지만, 테이블 랜덤 액세스 횟수를 줄여주기 때문이다.

```
SELECT 렌탈관리번호, 고객명, 서비스관리번호, 서비스번호, 예약접수일시
     , 방문국가코드1, 방문국가코드2, 방문국가코드3, 로밍승인번호, 자동로밍여부
FROM   로밍렌탈
WHERE  서비스번호 LIKE '010%'
AND    사용여부 = 'Y'

ROWS   ROW SOURCE OPERATION
------ --------------------------------------------------
  1909 TABLE ACCESS BY INDEX ROWID 로밍렌탈(cr=266968 pr=27830 pw=0 time= ...)
266476  INDEX RANGE SCAN 로밍렌탈_N2 (cr=1011 pr=900 pw=0 time=1893462 us)
```
- 위 SQL을 위해 '서비스번호' 단일 컬럼으로 구성된 인덱스(로밍렌탈_N2)를 사용했다. 인덱스를 스캔하고서 얻은 건수는 266,476건이다. 따라서 그 건수만큼 테이블을 랜덤 액세스했는데, 그 단계에서만 266,957(=266,968-1,011)개 블록을 읽었다. 이는 전체 블록 I/O의 99.6%를 차지하는 양이다. 총 소요시간은 49초에 이른다.
- 블록 I/O는 각 오퍼레이션 우측 괄호 안에 있는 cr 항목을 통해 확인할 수 있다.

<br/>

- 잠시 앞에서 공부했던 인덱스 클러스터링 팩터 효과를 확인하자면, 클러스터링 팩터가 좋은 인덱스를 이용하면, 테이블 인덱스량에 비해 블록 I/O가 훨씬 적게 발생한다.
- 위 사례에서는 테이블을 총 266,476번 방문하는 동안 블록 I/O가 266,957개 발생했다. 이를 통해 인덱스 클러스터링 팩터가 매우 안 좋은 상태임을 알 수 있다. 데이터량이 워낙 많다 보니 서비스번호 조건을 만족하는 데이터가 뿔뿔이 흩어져 있는 것이다.

<br/>

- 문제는 테이블을 총 266,476번 방문했지만, 최종 결과집합이 1.909건 뿐이라는 데에 있다. 테이블을 방문하고서 사용여부 = 'Y' 조건을 체크하는 과정에서 대부분 걸러진 것이다.

```
ROWS   ROW SOURCE OPERATION
------ --------------------------------------------------
  1909 TABLE ACCESS BY INDEX ROWID 로밍렌탈(cr=2902 pr=0 pw=0 time= ...)
  1909  INDEX RANGE SCAN 로밍렌탈_N2 (cr=1001 pr=0 pw=0 time=198557 us)
```
- 위는 로밍렌탈_N2 인덱스에 '사용여부' 컬럼을 추가하고 나서의 SQL 트레이스 결과다.
- 인덱스를 거쳐 테이블을 1,909번 방문했다. 모두 결과집합에 포함되었다. 불필요한 테이블 액세스가 전혀 발생하지 않았다.
- 불필요한 작업을 줄인 만큼 총 블록 I/O도 2,902개로 줄었다.


### 3.1.5 인덱스만 읽고 처리
- 테이블 랜덤 액세스가 아무리 많아도 필터 조건에 의해 버려지는 레코드가 거의 없다면 거기에 비효율은 없다. 들인 노력만큼 결과를 얻었기 때문이다. 이때는 어떻게 튜닝해야 할까?

```
SELECT 부서번호, SUM(수량)
FROM   판매집계
WHERE  부서번호 LIKE '12%'
GROUP BY 부서번호 ;
```
- 예를 들어, 위 SQL 쿼리에 부서번호 단일 컬럼으로 구성된 인덱스를 사용한다면, 비효율은 없다. 인덱스에서 부서번호 LIKE 조건에 해당하는 데이터를 찾고 테이블을 액세스한 후에 버리는 데이터가 하나도 없기 때문이다.
- 비효율이 없더라도 인덱스 스캔 과정에서 얻은 데이터가 많다면 그만큼 테이블 랜덤 액세스가 많이 발생하므로 성능이 느릴 수 밖에 없다. 쿼리나 인덱스에 문제가 있어서가 아니라 절대 일량이 많아서 느린 것이다.
- 반드시 성능을 개선해야 한다면, 쿼리에 사용된 컬럼을 모두 인덱스에 추가해서 테이블 액세스가 아예 발생하지 않게 하는 방법을 고려해 볼 수 있다.
- 인덱스만 읽어서 처리하는 쿼리를 `Covered 쿼리`라고 부르며, 그 쿼리에 사용한 인덱스를 `Covered 인덱스`라고 부른다.
- 위 SQl 쿼리는 다행히 컬럼이 많지 않다. '부서번호' 단일 컬럼으로 구성된 인덱스에 '수량' 컬럼만 추가하면 된다.
- 테이블 액세스를 제거하는순간, 성능은 획기적으로 좋아지지만 추가해야 할 컬럼이 많을 경우 적용하기 어렵다.

#### Include 인덱스
- Oracle에는 없지만, SQL Server 2005 버전에 추가된 기능 중 `Include 인덱스`라는 기능이 있다.
- 이것은 인덱스 키 외에 미리 지정한 컬럼은 리프 레벨에 함께 저장하는 기능이다.

```
CREATE INDEX EMP_X01 ON EMP (DEPTNO) INCLUDE (SAL)
```
- 인덱스를 생성할 때 위와 같이 INCLUDE 옵션을 지정하면 된다. 컬럼은 최대 1,023개까지 지정할 수 있다.

```
CREATE INDEX EMP_X02 ON EMP (DEPTNO, SAL)
```
- INCLUDE 옵션을 주고 생성한 EMP_X01 인덱스와 위 EMP_X02 인덱스는 어떤 차이가 있을까?
- EMP_X02 인덱스는 DEPTNO와 SAL 컬럼 모두 루트와 브랜치 블록에 저장한다. 둘 다 수직적 탐색에 사용할 수 있다.
- EMP_X01 인덱스는 SAL 컬럼을 리프 블록에만 저장한다. 수직적 탐색에는 DEPTNO만 사용하고, 수평적 탐색에는 SAL 컬럼도 필터 조건으로 사용할 수 있다. SAL 컬럼은 테이블 랜덤 액세스 횟수를 줄이는 용도로만 사용한다.

```
SELECT SAL FROM EMP WHERE DEPTNO = 20
```
- 위 SQL을 처리할 때, EMP_X01과 EMP_X02 둘 다 `Covered 인덱스`이므로 테이블 랜덤 액세스를 생략할 수 있다.

```
SELECT * FROM EMP WHERE DEPTNO = 20 AND SAL >= 2000
SELECT * FROM EMP WHERE DEPTNO = 20 AND SAL <= 3000
SELECT * FROM EMP WHERE DEPTNO = 20 AND SAL BETWEEN 2000 AND 3000
```
- 위 SQL을 처리할 때도 테이블 랜덤 액세스 측면에서는 일량이 똑같다. 두 인덱스 모두 불필요한 테이블 액세스가 발생하지 않는다. 하지만 인덱스 스캔량은 EMP_X02 인덱스가 더 적다. SAL 컬럼도 인덱스 액세스 조건으로 사용하기 때문이다.

```
SELECT * FROM EMP WHERE DEPTNO = 20 ORDER BY SAL
```
- 위 SQL을 처리할 때 EMP_X02 인덱스는 소트 연산을 생략할 수 있지만, EMP_X01 인덱스는 생략할 수 없다.
- INCLUDE 인덱스는 순전히 테이블 랜덤 액세스를 줄이는 용도로 개발됐다.


### 3.1.6 인덱스 구조 테이블
- 인덱스를 이용한 테이블 액세스가 고비용 구조라면, 랜덤 액세스가 아예 발생하지 않도록 테이블을 인덱스 구조로 생성하면 어떨까? 오라클에서는 이 방법을 `IOT(Index-Organized Table)`라고 부른다. 참고로 MS-SQL Server는 `클러스터형(Clustered) 인덱스`라고 부른다.
- 테이블을 찾아가기 위한 ROWID를 갖는 일반 인덱스와 달리 IOT는 그 자리에 테이블 데이터를 갖는다. 즉 테이블 블록이 있어야 할 데이터를 인덱스 리프 블록에 모두 저장하고 있다.

![그림3-11](https://github.com/user-attachments/assets/f6b48937-3d83-47a9-984a-6b9759ae11e8)
- 위 그림에서 알 수 있는 것처럼 IOT에서는 `인덱스 리프 블록이 곧 데이터 블록`이다.

```
CREATE TABLE INDEX_ORG_T ( A NUMBER, B VARCHAR(10), CONSTRAINT INDEX_ORG_T_PK PRIMARY KEY (A) )
ORGANIZATION INDEX ;
```
- 테이블을 인덱스 구조로 만드는 구문은 위와 같다.

```
CREATE TABLE HEAP_ORG_T ( A NUMBER, B VARCHAR(10), CONSTRAINT HEAP_ORG_T_PK PRIMARY KEY (A) )
ORGANIZATION HEAP ;
```
- 참고로 일반 테이블은 `힙 구조 테이블`이라고 부른다. 테이블을 생성할 때 대개 생략하지만, 위와 같이 ORGANIZATION 옵션을 명시할 수도 있다.
- 일반 힙 구조 테이블에 데이터를 입력할 때는 랜덤 방식을 사용한다. 즉, Freelist로부터 할당 받은 블록에 정해진 순서 없이 데이터를 입력한다.
- 반면, IOT는 인덱스 구조 테이블이므로 정렬 상태를 유지하며 데이터를 입력한다.

<br/>

- IOT는 인위적으로 클러스터링 팩터를 좋게 만드는 방법 중 하나다. 같은 값을 가진 레코드들이 100% 정렬된 상태로 모여 있으므로 랜덤 액세스가 아닌 시퀀셜 방식으로 데이터를 액세스한다. 이 때문에 BETWEEN이나 부등호 조건으로 넓은 범위를 읽을 때 유리하다.
- 데이터 입력과 조회 패턴이 서로 다른 테이블에도 유용하다. 예를 들어, 어떤 회사에 영업사원이 100명이라고 가정하자. 영업사원들의 일별 실적을 집계하는 테이블이 있는데, 한 블록에 100개 레코드가 담긴다. 그러면 매일 한 블록씩 1년이면 365개 블록이 생긴다.

```
SELECT SUBSTR(일자, 1, 6) 월도
     , SUM(판매금액) 총판매금액, AVG(판매금액) 평균판매금액
FROM   영업실적
WHERE  사번 = 'S1234'
AND    일자 BETWEEN '20180101' AND '20181231'
GROUP BY SUBSTR(일자, 1, 6)
``` 
- 실적등록은 일자별로 진행되지만, 실적조회는 주로 사원별로 이루어진다.
- 위 쿼리를 영업부서에서 가장 많이 수행한다고 가정하자. 이 쿼리에 인덱스를 사용한다면, 사원마다 랜덤 액세스 방식으로 365개 테이블 블록을 읽어야 한다. 클러스터링 팩터가 매우 안 좋으므로 조회 건수만큼 블록 I/O가 발생한다.

```
CREATE TABLE 영업실적 ( 사번 VARCHAR2(5), 일자 VARCHAR2(8), ...
       , CONSTRAINT 영업실적_PK PRIMARY KEY (사번, 일자) ) ORGANIZATION INDEX ;
```
- 이처럼 입력과 조회 패턴이 서로 다를 때, 위와 같이 사번이 첫 번째 정렬 기준이 되도록 IOT를 구성해 주면, (한 블록에 100개 레코드가 담기므로) 네 개 블록만 읽고 처리할 수 있다.


### 3.1.7 클러스터 테이블

#### 인덱스 클러스터 테이블
- 인덱스 클러스터 테이블은 클러스터 키 값이 같은 레코드를 한 블록에 모아서 저장하는 구조다.
- 한 블록에 모두 담을 수 없을 때는 새로운 블록을 할당해서 클러스터 체인으로 연결한다.
- 심지어 여러 테이블 레코드를 같은 블록에 저장할 수도 있는데, 이를 `다중 테이블 클러스터`라고 부른다. 일반 테이블은 하나의 데이터 블록을 여러 테이블이 공유할 수 없음을 상기하자.
- 클러스터형 인덱스는 IOT에 가깝다. 오라클 클러스터는 키 값이 같은 데이터를 같은 공간에 저장해 둘 뿐, IOT나 SQL Server의 클러스터형 인덱스처럼 정렬하지는 않는다.

```
CREATE CLUSTER C_DEPT# ( DEPTNO NUMBER(2) ) INDEX ;
```
- 인덱스 클러스터 테이블을 구성하려면 먼저 위와 같이 클러스터를 생성한다.

```
CREATE INDEX C_DEPT#_IDX ON CLUSTER C_DEPT# ;
```
- 클러스터에 테이블을 담기 전에 위와 같이 클러스터 인덱스를 반드시 정의해야 한다.
- 왜냐하면 클러스터 인덱스는 데이터 검색 용도로 사용할 뿐만 아니라 데이터가 저장될 위치를 찾을 때도 유용하기 때문이다.

```
CREATE TABLE DEPT (
    DEPTNO NUMBER(2) NOT NULL
    , DNAME VARCHAR2(14) NOT NULL
    , LOC VARCHAR2(13) )
CLUSTER C_DEPT#( DEPTNO ) ;
```
- 클러스터 인덱스를 만들었으면 위와 같이 클러스터 테이블을 생성한다.

![그림3-13](https://github.com/user-attachments/assets/462b9ef5-cfa2-4a32-b40f-6d4fb266d600)
- 클러스터 인덱스도 B*Tree 인덱스 구조를 사용하지만, 테이블 레코드를 일일이 가리키지 않고 해당 키 값을 저장하는 첫 번째 데이터 블록을 가리킨다는 점이 다르다.
- 즉, 일반 테이블에 생성한 인덱스 레코드는 테이블 레코드와 1:1 대응 관계를 맺지만, 클러스터 인덱스는 테이블 레코드와 1:M 관계를 갖는다. 따라서 클러스터 인덱스의 키 값은 항상 Unique하다(중복 값이 없다).
- 이런 구조적 특성 때문에 클러스터 인덱스를 스캔하면서 값을 찾을 때는 랜덤 액세스가 (클러스터 체인을 스캔하면서 발생하는 랜덤 액세스는 제외하고) 값 하나당 한 번씩 밖에 발생하지 않는다.
- 클러스터에 도달해서는 시퀀셜 방식으로 스캔하기 때문에 넓은 범위를 읽더라도 비효율이 없다는 게 핵심 원리다.

#### 해시 클러스터 테이블

![그림3-14](https://github.com/user-attachments/assets/4ebbc747-f9cc-43da-a784-c56830148ba2)
- 해시 클러스터는 인덱스를 사용하지 않고 해시 알고리즘을 사용해 클러스터를 찾아간다는 점만 다르다.

```
CREATE CLUSTER C_DEPT# ( DEPTNO NUMBER(2) ) HASHKEYS 4 ;
```
- 해시 클러스터 테이블을 구성하려면 위와 같이 클러스터를 생성한다.

```
CREATE TABLE DEPT (
    DEPTNO NUMBER(2) NOT NULL
    , DNAME VARCHAR2(14) NOT NULL
    , LOC VARCHAR2(13) )
CLUSTER C_DEPT# ( DEPTNO ) ;
```
- 그리고 위와 같이 클러스터 테이블을 생성한다.


## 3.2 부분범위 처리 활용


### 3.2.1 부분범위 처리
- DBMS가 클라이언트에게 데이터를 전송할 때 일정량씩 나누어 전송한다. 전체 결과집합 중 아직 전송하지 않은 분량이 많이 남아있어도 서버 프로세스는 클라이언트로부터 추가 Fetch Call을 받기 전까지 그대로 멈춰 서서 기다린다.

```
private void execute(Connection con) throws Exception {
    Statement stmt = con.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT NAME FROM BIG_TABLE");

    for(int i = 0; i < 100; i++) {
        if(rs.next()) {
            System.out.println("rs.getString(1));
        }
    }

    rs.close();
    stmt.close();
}
```
- 위 Java 메소드에서 호출하는 BIG_TABLE이 1억 건에 이르는 대용량 테이블이어도 실행 결과는 곧바로 출력된다. 이유는, DBMS가 데이터를 모두 읽어 한 번에 전송하지 않고 먼저 읽는 데이터부터 일정량(Array Size)을 전송하고 멈추기 때문이다.
- 데이터를 전송하고 나면 서버 프로세스는 CPU를 OS에 반환하고 대기 큐에서 잠을 잔다. 다음 Fetch Call을 받으면 대기 큐에서 나와 그다음 데이터부터 일정량을 읽어서 전송하고 또다시 잠을잔다.
- 이처럼 전체쿼리 결과집합을 쉼 없이 연속적으로 전송하지 않고 사용자로부터 Fetch Call이 있을 때마다 일정량씩 나누어 전송하는 것을 이른바 `부분범위 처리`라고 한다.
- 데이터를 전송하는 단위인 Array Size는 클라이언트 프로그램에서 설정한다. JAVA에서 Array Size 기본값은 10이며, Statement 객체 setFetchSize 메소드를 통해 설정을 변경할 수 있다.
- Array Size가 10인 상태에서 Java 프로그램이 데이터를 읽어 들이는 메커니즘은 아래와 같다.
    - 1. 최초 rs.next() 호출 시 Fetch Call을 통해 DB 서버로부터 전송받은 데이터 10건을 클라이언트 캐시에 저장한다.
    - 2. 이후 rs.next() 호출할 때는 Fetch Call을 발생시키지 않고 캐시에서 데이터를 읽는다.
    - 3. 캐시에 저장한 데이터를 모두 소진한 상태에서 rs.next() 호출 시 추가 Fetch Call을 통해 10건을 전송받는다.
    - 4. 100건을 다 읽을 때까지 2~3번 과정을 반복한다.
- 100개 레코드를 전송받아 콘솔에 출력(내부적으로 연속해서 10번의 Fetch Call 발생)하고는 곧바로 ResultSet과 Statement 객체를 닫았으므로 위 Java 프로그램은 BIG_TABLE에 데이터가 아무리 많아도 오래 걸릴 이유가 없다.

#### 정렬 조건이 있을 때 부분범위 처리
```
    Statement stmt = con.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT NAME FROM BIG_TABLE ORDER BY CREATED");
```
- 쿼리문에 ORDER BY를 추가하면 DB 서버는 **모든** 데이터를 다 읽어 CREATED 순으로 정렬을 마치고서야 클라이언트에게 데이터 전송을 시작할 수 있다. 부분범위가 아닌 전체범위 처리로 동작한다. Sort Area와 Temp 테이블스페이스까지 이용해 데이터 정렬을 마치고 나면 그때부터 일정량씩 나눠 클라이언트에게 데이터를 전송한다.
- 다행히 CREATED 컬럼이 선두인 인덱스가 있으면, 부분범위 처리가 가능하다. 인덱스는 항상 정렬된 상태를 유지하므로 전체 데이터를 정렬하지 않고도 정렬된 상태의 결과집합을 바로 전송할 수 있기 때문이다.


#### Array Size 조정을 통한 Fetch Call 최소화
- 대량 데이터를 파일로 내려받는 경우에는 어차피 데이터를 모두 전송해야 하므로 가급적 Array Size 값을 크게 설정해야 한다. Array Size를 조정한다고 해서 전송해야 할 총량이 변하진 않지만, Fetch Call 횟수를 그만큼 줄일 수 있다.
- 반대로, 앞쪽 일부 데이터만 Fetch하다가 멈추는 프로그램이라면 Array Size를 작게 설정하는 것이 유리하다. 불필요하게 많은 데이터를 전송하고 버리는 비효율을 줄일 수 있기 때문이다.
- 100개 레코드만 필요한 Java 프로그램에서 Array Size를 1,000으로 설정한다면, 사용하지도 않고 버릴 뒤쪽 900개 레코드를 읽어서 전송하는 과정에 네트워크와 서버, 클라이언트 자원만 낭비하게 된다.


### 3.2.2 부분범위 처리 구현
- 아래 Java 소스는 부분범위 처리를 활용하지 않은 예시다.
```
public class AllRange {
    
    public static void execute(Connection con) throws Exception {
        int arraysize = 10;

        String SQLStmt = "SELECT OBJECT_ID, OBJECT_NAME FROM ALL_OBJECTS";
        Statement stmt = con.createStatement();
        stmt.setFetchSize(arraysize);

        ResultSet rs = stmt.executeQuery(SQLStmt);
        while(rs.next()) {
            System.out.println(rs.getLong(1) + " : " + rs.getString(2));
        }
        rs.close();
        stmt.close();
    }

    public static void main(String[] args) throws Exception {
        Connection con = getConnection();
        execute(con);
        releaseConnection(con);
    }

}
```

- 아래 Java 소스는 부분범위 처리를 활용한 예시다. 출력 레코드 수가 Array Size에 도달하면 멈추었다가 사용자 요청이 있을 때 다시 데이터를 Fetch하는 부분이 있다. 보통은 개발 프레임워크에 미리 구현돼 있는 기능을 활용한다.

```
import java.io.*;
import java.lang.*;
import java.util.*;
import java.net.*;
import java.sql.*;
import oracle.jdbc.driver.*;

public class PartialRange {

    public static int fetch(ResultSet rs, int arraysize) throws Exception {
        int i = 0;
        while(rs.next()) {
            System.out.println(rs.getLong(1) + " : " + rs.getString(2));
            if(++i >= arraysize) return i;
        }
        return i;
    }
    
    public static void execute(Connection con) throws Exception {
        int arraysize = 10;

        String SQLStmt = "SELECT OBJECT_ID, OBJECT_NAME FROM ALL_OBJECTS";
        Statement stmt = con.createStatement();
        stmt.setFetchSize(arraysize);

        ResultSet rs = stmt.executeQuery(SQLStmt);
        while(rs.next()) {
            int r = fetch(rs, arraysize);
            if(r < arraysize) break;
            System.out.println("Enter to Continue ... (Q)uit?");
            
            BufferedReader in = new BufferedReader(new InputStreamReader(System.in));
            String input = in.readLine();
            if(input.equals("Q")) break;
        }
        rs.close();
        stmt.close();
    }

    public static void main(String[] args) throws Exception {
        Connection con = getConnection();
        execute(con);
        releaseConnection(con);
    }

}
```


### 3.2.3 OLTP 환경에서 부분범위 처리에 의한 성능개선 원리
- `OLTP(Online Transaction Processing)` 시스템은 일반적으로 소량 데이터를 읽고 갱신하는 `온라인 트랜잭션`을 처리하는 시스템이다.
- 인덱스를 이용해 수천수만 건을 조회할 경우 만족할만한 성능을 내기 어려울 수 있다. 많은 랜덤 테이블 액세스가 발생하기 때문이다. 우연히 버퍼캐시히트율이 좋다면 빠른 성능을 보일 수도 있지만, 그렇지 않다면 수십 초간 기다려야 할 수도 있다.
- OLTP성 업무에서 쿼리 결과 집합이 아주 많을 때 사용자가 모든 데이터를 일일이 다 확인하지는 않는다. 특정한 정렬 순서로 상위 일부 데이터만 확인한다.
- 주로 목록을 조회하는 경우(은행계좌 입출금 조회, 뉴스 또는 게시판(BBS) 조회 등)이며, 이럴 때 항상 정렬 상태를 유지하는 인덱스를 이용하면, 정렬 작업을 생략하고 앞쪽 일부 데이터를 아주 빠르게 보여줄 수 있다.

```
SELECT 게시글ID, 제목, 작성자, 등록일시
FROM   게시판
WHERE  게시판구분코드 = 'A'
ORDER BY 등록일시 DESC
```
- 위 SQL 쿼리에서 인덱스 선두 컬럼을 `게시판구분코드 + 등록일시` 순으로 구성하지 않으면(게시판구분코드 단일 컬럼으로 구성하거나, 게시판구분코드 바로 뒤에 등록일시가 위치하지 않으면), 소트 연산을 생략할 수 없다.
- 게시판구분코드 = 'A' 조건을 만족하는 모든 레코드를 인덱스에서 읽어야 하고, 그만큼 많은 테이블 랜덤 액세스가 발생한다. 모든 데이터를 다 읽어 등록일시 역순으로 정렬을 마치고서야 출력을 시작하므로 OLTP 환경에서 요구되는 빠른 응답 속도를 내기 어렵다.

```
ID | OPERATION                       | NAME | ROWS  | BYETS | COST
-------------------------------------------------------------------
 0 | SELECT STATEMENT                |      | 40000 | 3515K | 2041
 1 |  SORT ORDER BY                  |      | 40000 | 3515K | 2041
 2 |   TABLE ACCESS BY INDEX ROWID   |      | 40000 | 3515K | 1210
 3 |    INDEX RANGE SCAN             |      | 40000 |       | 96
```
- 위 실행계획은 인덱스로 소트 연산을 생략할 수 없을 때 나타난다.

```
ID | OPERATION                       | NAME       | ROWS | BYETS | COST
-------------------------------------------------------------------
 0 | SELECT STATEMENT                |           | 40000 | 3515K | 1372
 1 |  TABLE ACCESS BY INDEX ROWID    | 게시판     | 40000 | 3515K | 1372
 2 |   INDEX RANGE SCAN DESCENDING   | 게시판_X02 | 40000 |       | 258
```
- 위 실행계획은 인덱스를 `게시판구분코드 + 등록일시`순으로 구성하여 Sory Order by 연산을 생략한 실행계획이다. SQL문에 Order By 절이있음에도 불구하고 Sort Order By 오퍼레이션이 자동으로 제거되었다.


#### 멈출 수 있어야 의미있는 부분범위 처리
- **문제는 앞쪽 일부만 출력하고 멈출 수 있는가이다**. 이것이 부분범위 처리의 핵심이다.
- 토드나 오렌지 같은 쿼리 툴은 이미 그렇게 구현이 되어있다. 클라이언트 프로그램이 DB 서버에 직접 접속하는 2-Tier 환경에서는 그렇게 구현할 수 있었고, 실제로도 그렇게 많이 구현했었다.
- 그런데 클라이언트와 DB 서버 사이에 WAS, AP 서버 등이 존재하는 n-Tier 아키텍처에서는 클라이언트가 특정 DB 커넥션을 독점할 수없다. 단위 작업을 마치면 DB 커넥션을 곧바로 커넥션 풀에 반환해야 하므로 그 전에 SQL 조회 결과를 클라이언트에게 **모두** 전송하고 커서(Cursor)를 닫아야 한다. 따라서 SQL 결과집합을 조금씩 나눠 전송하도록 구현하기 어렵다.