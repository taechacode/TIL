# 3장 인덱스 튜닝

## 3.1 테이블 액세스 최소화
- SQL 튜닝은 랜덤 I/O와의 전쟁이다.
- SQL 성능 향상을 위해 DBMS가 제공하는 많은 기능이 느린 랜덤 I/O를 극복하기 위해 개발됐고, 조인 메소드의 발전은 물론 많은 튜닝 기법도 랜덤 I/O 최소화에 맞춰져 있다.


### 3.1.1 테이블 랜덤 액세스

#### 인덱스 ROWID는 물리적 주소? 논리적 주소?
```
SELECT * FROM 고객 WHERE 지역 = '서울' ;

Execution Plan
----------------------------------------
0   SELECT STATEMENT Optimizer=ALL_ROWS
1 0  TABLE ACCESS BY INDEX ROWID OF '고객' (TABLE)
2 1   INDEX RANGE SCAN OF '고객_지역_IDX' (INDEX)
```
- SQL이 참조하는 컬럼을 인덱스가 모두 포함하는 경우가 아니라면, 인덱스를 스캔한 후에 반드시 테이블을 액세스한다. 위 실행계획에서 `TABLE ACCESS BY INDEX ROWID`라고 표시된 부분이 여기에 해당한다.
- 인덱스를 스캔하는 이유는, 검색 조건을 만족하는 소량의 데이터를 인덱스에서 빨리 찾고 거기서 테이블 레코드를 찾아가기 위한 주소값인 ROWID를 얻으려는 데 있다.
- 그렇다면 인덱스 ROWID는 물리적 주소일까, 논리적 주소일까? 인덱스 ROWID는 물리적 주소보다 논리적 주소에 가깝다. 물리적으로 직접 연결되지 않고 테이블 레코드를 찾아가기 위한 논리적 주소 정보를 담고 있기 때문이다.
- 데이터베이스 인덱스를 설명할 때 항상 도서 색인에 비유한다. 색인에 기록된 페이지 번호가 ROWID에 해당한다.
- 인덱스 ROWID를 포인터라고 생각하는 경우도 있다. 하지만 메모리 주소값을 담는 포인터는 메모리상 데이터를 찾아가는 데 있어 비용이 0에 가깝고, 사실상 물리적으로 직접 연결된 구조와 다름없다. 인덱스는 ROWID는 포인터가 아니다.
- 인덱스 ROWID는 논리적 주소다. 디스크 상에서 테이블 레코드를 찾아가기 위한 위치 정보를 담는다. 테이블 레코드과 물리적으로 직접 연결된 구조가 아니다.

#### 메인 메모리와 DB 비교
- 메인 메모리 DB(MMDB)는 데이터를 모두 메모리에 로드해 놓고 메모리를 통해서만 I/O를 수행하는 DB이다.
- 잘 튜닝된 OLTP성 데이터베이스 시스템이라면 버퍼캐시 히트율이 99% 이상이다. 디스크를 경유하지 않고 대부분 데이터를 메모리에서 읽는다는 뜻이다. 하지만 메인 메모리 DB만큼 빠르지는 않다. 특히 대량 데이터를 인덱스로 액세스할 때는 엄청난 차이가 난다.
- 벤더에 따라 내부 아키텍처가 모두 다르겠지만, 어떤 메인 메모리 DB의 경우 인스턴스를 기동하면 디스크에 저장된 데이터를 버퍼캐시로 로딩하고 이어서 인덱스를 생성한다. 이때 인덱스는 오라클처럼 디스크 상의 주소정보를 갖는게 아니라 메모리상의 주소정보, 즉 포인터(pointer)를 갖는다. 따라서 인덱스를 경유해 테이블을 액세스하는 비용이 오라클과 비교할 수 없을 정도로 낮다.
- 오라클은 테이블 블록이 수시로 버퍼캐시에서 밀려났다가 다시 캐싱되며, 그때마다 다른 공간에 캐싱되기 때문에 인덱스에서 포인터로 직접 연결할 수 없는 구조다. 메모리 주소 정보(포인터)가 아닌 디스크 주소 정보(DBA, Data Block Address)를 이용해 해시 알고리즘으로 버퍼 블록을 찾아간다.

#### I/O 메커니즘 복습
- DBA(데이터파일번호 + 블록번호)는 디스크 상에서 블록을 찾기 위한 주소 정보다.
- 매번 디스크에서 블록을 읽을 수는 없기에, I/O 성능을 높이려면 버퍼캐시를 활용해야 한다. 그래서 블록을 읽을 때는 디스크로 가기 전에 버퍼캐시부터 찾아본다. 읽고자 하는 DBA를 해시 함수에 입력해서 해시 체인을 찾고 거기서 버퍼 헤더를 찾는다.
- 캐시에 적재할 때와 읽을 때 같은 해시 함수를 사용하므로 버퍼 헤더는 항상 같은 해시 체인에 연결된다. 반면, 실제 데이터가 담긴 버퍼 블록은 매번 다른 위치에 캐싱되는데, 그 메모리 주소값을 버퍼 헤더가 가지고 있다.
- 정리하면, 해싱 알고리즘으로 버퍼 헤더를 찾고, 거기서 얻은 포인터로 버퍼 블록을 찾아간다.
- 인덱스로 테이블 블록을 액세스할 때는 리프 블록에서 얻은 ROWID를 분해해서 DBA 정보를 얻고, 테이블을 FULL SCAN 할 때는 익스텐트 맵을 통해 읽을 블록들의 DBA 정보를 얻는다.
- 인덱스 ROWID는 물리적 주소가 아니라 디스크 상에서 테이블 레코드를 찾아가기 위한 논리적인 주소 정보다. ROWID가 가리키는 테이블 블록을 버퍼캐시에서 먼저 찾아보고, 못 찾을 때만 디스크에서 블록을 읽는다. 물론 버퍼캐시에 적재한 후에 읽는다.
- 설령 모든 데이터가 캐싱돼 있더라도 테이블 레코드를 찾기 위해 매번 DBA 해싱과 래치 획득 과정을 반복해야 한다. 동시 액세스가 심할 때는 캐시버퍼 체인 래치와 버퍼 Lock에 대한 경합까지 발생한다. 이처럼 인덱스 ROWID를 이용한 테이블 액세스는 고비용 구조다.

#### 인덱스 ROWID는 우편주소
- 디스크 DB(오라클, SQL Server 같은 일반 DBMS)가 사용하는 ROWID를 우편주소에, 메인 메모리 DB가 사용하는 포인터를 전화번호에 비유할 수 있다.
    - 전화통신은 물리적으로 연결된 통신망을 이용하므로 전화번호를 누르면 곧바로 상대방과 통화할 수 있다.
    - 하지만 우편통신은 봉투에 적힌 대로 우체부가 일일이 찾아다니는 구조이므로 전화와는 비교할 수 없이 느리다.


### 3.1.2 인덱스 클러스터링 팩터
- 클러스터링 팩터(Clustering Factor, 이하 'CF')는 '군집성 계수'로 번역할 수 있는 용어로서, 특정 컬럼을 기준으로 같은 값을 갖는 데이터가 모여있는 정도를 의미한다. CF가 좋은 컬럼에 생성한 인덱스는 검색 효율이 매우 좋다.
    - 예를 들어 `거주지역 = '제주'`에 해당하는 고객 데이터가 물리적으로 근접해 있으면 흩어져 있을 때보다 데이터를 찾는 속도가 빠르다.

![그림3-4](https://github.com/user-attachments/assets/70dc9c51-13df-4112-9bd1-bc5c9a016089)
- 위 그림은 인덱스 클러스터링 팩터가 가장 좋은 상태를 도식화한 것으로서, 인덱스 레코드 정렬 순서와 테이블 레코드 정렬 순서가 100% 일치하는 것을 볼 수 있다.

![그림3-5](https://github.com/user-attachments/assets/0a4a5b58-35b6-49ab-af81-924e02fc0a19)
- 반면, 위 그림은 인덱스 클러스터링 팩터가 안 좋은 상태를 도식화한 것으로서, 인덱스 레코드 정렬 순서와 테이블 레코드 정렬 순서가 일치하지 않는다.

#### 인덱스 클러스터링 팩터 효과
- CF가 좋은 컬럼에 생성한 인덱스는 검색 효율이 좋다고 했는데, 이는 테이블 액세스량에 비해 블록 I/O가 적게 발생함을 의미한다.
- 그렇다면 인덱스 레코드마다 테이블 레코드를 건건이 블록 단위로 I/O 한다면, CF가 달라도 블록 I/O 발생량에 차이가 없어야 하지 않을까?
- 인덱스 ROWID로 테이블을 액세스할 때, 오라클은 래치 획득과 해시 체인 스캔 과정을 거쳐 어렵게 찾아간 테이블 블록에 대한 포인터(메모리 주소값)를 바로 해제하지 않고 일단 유지한다. 이를 `버퍼 Pinning`이라고 부른다.
- 이 상태에서 다음 인덱스 레코드를 읽었는데, 마침 **직전과 같은** 테이블 블록을 가리킨다. 그러면 래치 획득과 해시 체인 스캔 과정을 생략하고 바로 테이블 블록을 읽을 수 있다. 논리적인 블록 I/O 과정을 생략할 수 있는 것이다.

![그림3-6](https://github.com/user-attachments/assets/b9f3cddb-c843-4dcc-9b94-0b9e08ab4ae8)
- 위 그림은 CF가 좋은 인덱스를 사용할 때 테이블 액세스 횟수에 비해 블록 I/O가 적게 발생하는 이유를 잘 설명해준다. 굵은 실선이 실제 블록 I/O가 발생하는 경우다. 가는 점선은 논리적인 블록 I/O 없이 포인터로 바로 액세스하는 경우다.
- 만약 CF가 안 좋은 인덱스를 사용하면 테이블을 액세스하는 횟수만큼 고스란히 블록 I/O가 발생한다.


### 3.1.3 인덱스 손익분기점
- 인덱스 ROWID를 이용한 테이블 액세스는 생각보다 고비용 구조다. 읽어야 할 데이터가 일정량을 넘는 순간, 테이블 전체를 스캔하는 것보다 오히려 느려진다. Index Range Scan에 의한 테이블 액세스가 Table Full Scan보다 느려지는 지점을 흔히 `인덱스 손익분기점`이라고 부른다.
- Table Full Scan은 성능이 일정하다. 전체 1,000만 건 중 한 건을 조회하든, 10만 건을 조회하든, 1000만 건을 다 조회하든 차이가 거의 없다.
- 인덱스를 이용해 테이블을 액세스할 때는 전체 1,000만 건 중 몇 건을 추출하느냐에 따라 성능이 크게 달라진다. 당연히 추출 건수가 많을수록 느려진다. 테이블 랜덤 액세스 때문이다.
- 인덱스를 이용한 테이블 액세스가 Table Full Scan보다 더 느려지게 만드는 가장 핵심적인 두 가지 요인은 다음과 같다.
    - Table Full Scan은 시퀀셜 액세스인 반면, 인덱스 ROWID를 이용한 테이블 액세스는 랜덤 액세스 방식이다.
    - Table Full Scan은 Multiblock I/O인 반면, 인덱스 ROWID를 이용한 테이블 액세스는 Sigle Block I/O 방식이다.

![그림3-8](https://github.com/user-attachments/assets/abd0b7d2-7d42-4d9c-bdf8-c04682928492)
- 인덱스 손익분기점은 보통 5~20%의 낮은 수준에서 결정된다.
- CF에 따라서 인덱스 손익분기점이 크게 달라진다. 인덱스 CF가 나쁘면 같은 테이블 블록을 여러 번 반복 액세스하면서 논리적 I/O 횟수가 늘고, 물리적 I/O 횟수도 늘기 때문이다.
- CF가 나쁘면 손익분기점은 5% 미만에서 결정되며, 심할 때는(BCHR이 매우 안 좋을 때) 1% 미만으로 낮아진다. 반대로 CF가 아주 좋을 때(인위적으로 전체 데이터를 인덱스 컬럼 순으로 정렬해서 재입력 했을 때)는 손익분기점이 90% 수준까지 올라가기도 한다.

#### 인덱스 손익분기점과 버퍼캐시 히트율
- 일반적으로 말하는 5~20% 수준의 손익분기점은 10만 건 이내, 많아 봐야 100만 이내 테이블에나 적용되는 수치다. 1,000만 건 수준의 큰 테이블에서는 손익분기점이 더 낮아진다.
- 예를 들어, 10만 건 테이블에서 10%는 1만 건이다. 1만 건 정도면 버퍼캐시에서 데이터를 찾을 가능성이 어느 정도 있다. 그리고 인덱스 컬럼 기준으로 값이 테이블 레코드가 근처에 모여 있을 가능성이 있다. 따라서 인덱스를 스캔하면서 테이블을 액세스하다 보면 어느 순간부터 대부분 테이블 블록을 캐시에서 찾게 된다.
- 1,000만 건 테이블에서는 10%면 100만 건이다. 많은 트랜잭션이 버퍼캐시를 동시에 사용하는 운영 시스템에서 100만 건 데이터를 인덱스로 추출하면 최초 조회 시에는 시간이 많이 걸린다. 조회 건수가 늘어난 양에 비해 성능이 훨씬 더 느려지는 현상을 경험하게 된다. 조회 건수가 늘수록 데이터를 버퍼캐시에서 찾을 가능성이 작아지기 때문에 나타나는 현상이다.
- 버퍼캐시에 할당하는 메모리 크기가 점점 커지는 추세지만, 데이터베이스에 저장된 **전체** 테이블에 대해서 보통 수백만 개 블록을 캐싱하는 수준이다. 따라서 **특정** 테이블을 인덱스로 100만 건 이상 액세스한다면 캐시 히트율은 극히 낮을 수 밖에 없다.
- 1,000만 건 정도 테이블이면 인덱스 컬럼 기준으로 값이 같은 테이블 레코드가 근처에 모여 있을 가능성이 매우 작다. 인덱스를 스캔하면서 읽은 테이블 블록을 뒤에서 다시 읽을 가능성이 작기 때문에 거의 모든 데이터를 디스크에서 읽게 된다. 이런 상황이면 손익분기점 자체가 의미 없어진다.
- 1만 건만 넘어도 시퀀셜 액세스와 Multiblock I/O 방식, 즉 Table Full Scan 방식으로 읽는 게 빠를 수 있다.

#### 온라인 프로그램 튜닝 VS 배치 프로그램 튜닝
- 온라인 프로그램은 보통 소량 데이터를 읽고 갱신하므로 인덱스를 효과적으로 활용하는 것이 무엇보다 중요하다. 조인도 대부분 NL 방식을 사용한다. (NL 조인은 인덱스를 이용하는 조인 방식이다.) 인덱스를 이용해 소트 연산을 생략함으로써 부분범위 처리 방식으로 구현할 수 있다면, 온라인 환경에서 대량 데이터를 조회할 때도 아주 빠른 응답 속도를 낼 수 있다.
- 반면, 대량 데이터를 읽고 갱신하는 배치(Batch) 프로그램은 항상 전체범위 처리 기준으로 튜닝해야 한다. 즉, 처리대상 집합 중 일부를 빠르게 처리하는 것이 아니라 전체를 빠르게 처리하는 것을 목표로 삼아야 한다. 대량 데이터를 빠르게 처리하려면, 인덱스와 NL 조인보다 Full Scan과 해시 조인이 유리하다.

```
SELECT C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
FROM   고객 C, 고객변경이력 H
WHERE  C.실명확인번호 = :rmnno
AND    H.고객번호 = C.고객번호
AND    H.변경일시 = (SELECT MAX(변경일시)
                    FROM   고객변경이력 M
                    WHERE  고객번호 = C.고객번호
                    AND    변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
                    AND    변경일시 <  TRUNC(SYSDATE, 'MM'))
```
- 위 쿼리는 실명확인번호로 조회한 특정 고객의 최근 1년 이내 변경 이력 중 전월 말일 데이터를 출력한다.
- 실명확인번호 조건에 해당하는 데이터를 한 건이거나 소량이므로 인덱스와 NL 조인을 사용하는 위 방식이 효과적이다.

```
INSERT INTO 고객_임시
SELECT C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
FROM   고객 C, 고객변경이력 H
WHERE  C.고객구분코드 = 'A001'
AND    H.고객번호 = C.고객번호
AND    H.변경일시 = (SELECT MAX(변경일시)
                    FROM   고객변경이력 M
                    WHERE  고객번호 = C.고객번호
                    AND    변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
                    AND    변경일시 <  TRUNC(SYSDATE, 'MM'))
```
- 위 쿼리는 고객구분코드가 'A001'인 고객의 최근 1년 이내 변경 이력 중 전월 말일 데이터를 읽어 고객_임시 테이블에 입력한다.
- 전체 300만 명 중 고객구분코드를 만족하는 고객은 100만 명이다. 이럴 때 위와 같이 기존 실명확인번호 조건절을 고객구분코드 조건절로 바꿔서 직전과 같은 방식으로 수행하면 결코 빠른 성능을 낼 수 없다.

```
INSERT INTO 고객_임시
SELECT /*+ FULL(C) FULL(H) INDEX_FFS(M.고객변경이력)
           ORDERED NO_MERGE(M) USE_HASH(M) USE_HASH(H) */       
       C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
FROM   고객 C
     , (SELECT 고객번호, MAX(변경일시) 최종변경일시
        FROM   고객변경이력
        WHERE  변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
        AND    변경일시 <  TRUNC(SYSDATE, 'MM')
        GROUP BY 고객번호) M
    ,  고객변경이력 H
WHERE  C.고객구분코드 = 'A001'
AND    M.고객번호 = C.고객번호
AND    H.고객번호 = M.고객번호
AND    H.변경일시 = M.최종변경일시
```
- 쿼리를 위와 같이 변경하고 FULL SCAN과 해시 조인을 사용해야 효과적이다. 조건절에 해당하지 않는 고객 데이터, 1년을 초과한 이력 데이터까지 읽는 비효율이 있지만, 수행속도는 훨씬 빠르다.

```
INSERT INTO 고객_임시
SELECT 고객번호, 고객명, 전화번호, 주소, 상태코드, 변경일시
FROM (SELECT /*+ FULL(C) FULL(H) LEADING(C) USE_HASH(H) */    
       C.고객번호, C.고객명, H.전화번호, H.주소, H.상태코드, H.변경일시
       , RANK() OVER (PARTITION BY H.고객번호 ORDER BY H.변경일시 DESC) NO
      FROM   고객 C, 고객변경이력 H
      WHERE  C.고객구분코드 = 'A001'
      AND    H.변경일시 >= TRUNC(ADD_MONTHS(SYSDATE, -12), 'MM')
      AND    H.변경일시 <  TRUNC(SYSDATE, 'MM')
      AND    H.고객번호 = C.고객번호)
WHERE NO = 1
```
- 고객변경이력 테이블을 두 번 읽는 비효율을 없애려면, 위와 같이 윈도우 함수를 이용하면 된다.
- 대량 배치 프로그램에서는 인덱스보다 FULL SCAN이 효과적이지만, 초대용량 테이블을 FULL SCAN하면 상당히 오래 기다려야 하고 시스템에 주는 부담도 적지 않다. 따라서 배치 프로그램에서는 파티션 활용 전략이 매우 중요한 튜닝 요소이고, 병렬 처리까지 더할 수 있으면 더 좋다.
- 위 쿼리의 고객변경이력 테이블을 변경일시 기준으로 파티셔닝하면 변경일시 조건(최근 1년)에 해당하는 파티션만 골라서 FULL SCAN하므로 부담을 크게 줄일 수 있다.
- 파티션 테이블에도 인덱스를 사용할수 있지만, 월 단위로 파티션한 테이블에서 특정 월 또는 몇 개월 치 데이터를 조회할 때 인덱스는 좋은 선택이 아니다. 보름 또는 일주일 치 데이터를 조회하더라도 인덱스보다 FULL SCAN이 유리하며, 심지어 2~3일 데이터를 조회할 때도 FULL SCAN이 유리할수 있다. 테이블을 파티셔닝하는 이유는 결국 FULL SCAN을 빠르게 처리하기 위해서다.


### 3.1.4 인덱스 컬럼 추가
- 테이블 액세스 최소화를위해 가장 일반적으로 사용하는 튜닝 기법은 인덱스에 컬럼을 추가하는 것이다.
 
```
SELECT /*+ INDEX(EMP EMP_NO1) */ *
FROM   EMP
WHERE  DEPTNO = 30
AND    SAL >= 2000
```
- EMP 테이블에 현재 PK 이외에 `DEPTNO + JOB`순으로 구성한 EMP_X01 인덱스 하나만 있는 상태에서 위 SQL 쿼리를 수행하려고 한다.

![그림3-9](https://github.com/user-attachments/assets/59d1f365-44d6-4d71-b488-5fcf1694be9b)
- 위의 그림을 참고하면, 위 조건을 만족하는 사원이 단 한 명인데, 이를 찾기 위해 테이블을 여섯 번 액세스하였다.
- 인덱스 구성을 `DEPTNO + SAL`순으로 변경하면 좋겠지만, 실 운영 환경에서는 인덱스 구성을 변경하기가 절대 쉽지 않다.

```
SELECT * FROM EMP WHERE DEPTNO = 30 AND JOB = 'CLERK'
```
- 위 SQL과 같이 기존 인덱스를 사용하는 SQL이 있을 수 있기 때문이다.
- 결국 인덱스를 새로 만들어야겠지만 이런 식으로 인덱스를 추가하다 보면 테이블마다 인덱스가 수십 개씩 달려 배보다 배꼽이 더 커지게 된다. 인덱스 관리 비용이 증가함은 물론 DML 부하에 따른 트랜잭션 성능 저하가 생길 수 있다.

![그림3-10](https://github.com/user-attachments/assets/e89b0c09-1739-485f-98a7-ef98bcf95552)
- 이럴 때, 책의 그림(그림3-10)을 참고하면 기존 인덱스에 SAL 컬럼을 추가하는 것만으로 큰 효과를 얻을 수 있다.
- 인덱스 스캔량은 줄지 않지만, 테이블 랜덤 액세스 횟수를 줄여주기 때문이다.

```
SELECT 렌탈관리번호, 고객명, 서비스관리번호, 서비스번호, 예약접수일시
     , 방문국가코드1, 방문국가코드2, 방문국가코드3, 로밍승인번호, 자동로밍여부
FROM   로밍렌탈
WHERE  서비스번호 LIKE '010%'
AND    사용여부 = 'Y'

ROWS   ROW SOURCE OPERATION
------ --------------------------------------------------
  1909 TABLE ACCESS BY INDEX ROWID 로밍렌탈(cr=266968 pr=27830 pw=0 time= ...)
266476  INDEX RANGE SCAN 로밍렌탈_N2 (cr=1011 pr=900 pw=0 time=1893462 us)
```
- 위 SQL을 위해 '서비스번호' 단일 컬럼으로 구성된 인덱스(로밍렌탈_N2)를 사용했다. 인덱스를 스캔하고서 얻은 건수는 266,476건이다. 따라서 그 건수만큼 테이블을 랜덤 액세스했는데, 그 단계에서만 266,957(=266,968-1,011)개 블록을 읽었다. 이는 전체 블록 I/O의 99.6%를 차지하는 양이다. 총 소요시간은 49초에 이른다.
- 블록 I/O는 각 오퍼레이션 우측 괄호 안에 있는 cr 항목을 통해 확인할 수 있다.

<br/>

- 잠시 앞에서 공부했던 인덱스 클러스터링 팩터 효과를 확인하자면, 클러스터링 팩터가 좋은 인덱스를 이용하면, 테이블 인덱스량에 비해 블록 I/O가 훨씬 적게 발생한다.
- 위 사례에서는 테이블을 총 266,476번 방문하는 동안 블록 I/O가 266,957개 발생했다. 이를 통해 인덱스 클러스터링 팩터가 매우 안 좋은 상태임을 알 수 있다. 데이터량이 워낙 많다 보니 서비스번호 조건을 만족하는 데이터가 뿔뿔이 흩어져 있는 것이다.

<br/>

- 문제는 테이블을 총 266,476번 방문했지만, 최종 결과집합이 1.909건 뿐이라는 데에 있다. 테이블을 방문하고서 사용여부 = 'Y' 조건을 체크하는 과정에서 대부분 걸러진 것이다.

```
ROWS   ROW SOURCE OPERATION
------ --------------------------------------------------
  1909 TABLE ACCESS BY INDEX ROWID 로밍렌탈(cr=2902 pr=0 pw=0 time= ...)
  1909  INDEX RANGE SCAN 로밍렌탈_N2 (cr=1001 pr=0 pw=0 time=198557 us)
```
- 위는 로밍렌탈_N2 인덱스에 '사용여부' 컬럼을 추가하고 나서의 SQL 트레이스 결과다.
- 인덱스를 거쳐 테이블을 1,909번 방문했다. 모두 결과집합에 포함되었다. 불필요한 테이블 액세스가 전혀 발생하지 않았다.
- 불필요한 작업을 줄인 만큼 총 블록 I/O도 2,902개로 줄었다.


### 3.1.5 인덱스만 읽고 처리
- 테이블 랜덤 액세스가 아무리 많아도 필터 조건에 의해 버려지는 레코드가 거의 없다면 거기에 비효율은 없다. 들인 노력만큼 결과를 얻었기 때문이다. 이때는 어떻게 튜닝해야 할까?

```
SELECT 부서번호, SUM(수량)
FROM   판매집계
WHERE  부서번호 LIKE '12%'
GROUP BY 부서번호 ;
```
- 예를 들어, 위 SQL 쿼리에 부서번호 단일 컬럼으로 구성된 인덱스를 사용한다면, 비효율은 없다. 인덱스에서 부서번호 LIKE 조건에 해당하는 데이터를 찾고 테이블을 액세스한 후에 버리는 데이터가 하나도 없기 때문이다.
- 비효율이 없더라도 인덱스 스캔 과정에서 얻은 데이터가 많다면 그만큼 테이블 랜덤 액세스가 많이 발생하므로 성능이 느릴 수 밖에 없다. 쿼리나 인덱스에 문제가 있어서가 아니라 절대 일량이 많아서 느린 것이다.
- 반드시 성능을 개선해야 한다면, 쿼리에 사용된 컬럼을 모두 인덱스에 추가해서 테이블 액세스가 아예 발생하지 않게 하는 방법을 고려해 볼 수 있다.
- 인덱스만 읽어서 처리하는 쿼리를 `Covered 쿼리`라고 부르며, 그 쿼리에 사용한 인덱스를 `Covered 인덱스`라고 부른다.
- 위 SQl 쿼리는 다행히 컬럼이 많지 않다. '부서번호' 단일 컬럼으로 구성된 인덱스에 '수량' 컬럼만 추가하면 된다.
- 테이블 액세스를 제거하는순간, 성능은 획기적으로 좋아지지만 추가해야 할 컬럼이 많을 경우 적용하기 어렵다.

#### Include 인덱스
- Oracle에는 없지만, SQL Server 2005 버전에 추가된 기능 중 `Include 인덱스`라는 기능이 있다.
- 이것은 인덱스 키 외에 미리 지정한 컬럼은 리프 레벨에 함께 저장하는 기능이다.

```
CREATE INDEX EMP_X01 ON EMP (DEPTNO) INCLUDE (SAL)
```
- 인덱스를 생성할 때 위와 같이 INCLUDE 옵션을 지정하면 된다. 컬럼은 최대 1,023개까지 지정할 수 있다.

```
CREATE INDEX EMP_X02 ON EMP (DEPTNO, SAL)
```
- INCLUDE 옵션을 주고 생성한 EMP_X01 인덱스와 위 EMP_X02 인덱스는 어떤 차이가 있을까?
- EMP_X02 인덱스는 DEPTNO와 SAL 컬럼 모두 루트와 브랜치 블록에 저장한다. 둘 다 수직적 탐색에 사용할 수 있다.
- EMP_X01 인덱스는 SAL 컬럼을 리프 블록에만 저장한다. 수직적 탐색에는 DEPTNO만 사용하고, 수평적 탐색에는 SAL 컬럼도 필터 조건으로 사용할 수 있다. SAL 컬럼은 테이블 랜덤 액세스 횟수를 줄이는 용도로만 사용한다.

```
SELECT SAL FROM EMP WHERE DEPTNO = 20
```
- 위 SQL을 처리할 때, EMP_X01과 EMP_X02 둘 다 `Covered 인덱스`이므로 테이블 랜덤 액세스를 생략할 수 있다.

```
SELECT * FROM EMP WHERE DEPTNO = 20 AND SAL >= 2000
SELECT * FROM EMP WHERE DEPTNO = 20 AND SAL <= 3000
SELECT * FROM EMP WHERE DEPTNO = 20 AND SAL BETWEEN 2000 AND 3000
```
- 위 SQL을 처리할 때도 테이블 랜덤 액세스 측면에서는 일량이 똑같다. 두 인덱스 모두 불필요한 테이블 액세스가 발생하지 않는다. 하지만 인덱스 스캔량은 EMP_X02 인덱스가 더 적다. SAL 컬럼도 인덱스 액세스 조건으로 사용하기 때문이다.

```
SELECT * FROM EMP WHERE DEPTNO = 20 ORDER BY SAL
```
- 위 SQL을 처리할 때 EMP_X02 인덱스는 소트 연산을 생략할 수 있지만, EMP_X01 인덱스는 생략할 수 없다.
- INCLUDE 인덱스는 순전히 테이블 랜덤 액세스를 줄이는 용도로 개발됐다.


### 3.1.6 인덱스 구조 테이블
- 인덱스를 이용한 테이블 액세스가 고비용 구조라면, 랜덤 액세스가 아예 발생하지 않도록 테이블을 인덱스 구조로 생성하면 어떨까? 오라클에서는 이 방법을 `IOT(Index-Organized Table)`라고 부른다. 참고로 MS-SQL Server는 `클러스터형(Clustered) 인덱스`라고 부른다.
- 테이블을 찾아가기 위한 ROWID를 갖는 일반 인덱스와 달리 IOT는 그 자리에 테이블 데이터를 갖는다. 즉 테이블 블록이 있어야 할 데이터를 인덱스 리프 블록에 모두 저장하고 있다.

![그림3-11](https://github.com/user-attachments/assets/f6b48937-3d83-47a9-984a-6b9759ae11e8)
- 위 그림에서 알 수 있는 것처럼 IOT에서는 `인덱스 리프 블록이 곧 데이터 블록`이다.

```
CREATE TABLE INDEX_ORG_T ( A NUMBER, B VARCHAR(10), CONSTRAINT INDEX_ORG_T_PK PRIMARY KEY (A) )
ORGANIZATION INDEX ;
```
- 테이블을 인덱스 구조로 만드는 구문은 위와 같다.

```
CREATE TABLE HEAP_ORG_T ( A NUMBER, B VARCHAR(10), CONSTRAINT HEAP_ORG_T_PK PRIMARY KEY (A) )
ORGANIZATION HEAP ;
```
- 참고로 일반 테이블은 `힙 구조 테이블`이라고 부른다. 테이블을 생성할 때 대개 생략하지만, 위와 같이 ORGANIZATION 옵션을 명시할 수도 있다.
- 일반 힙 구조 테이블에 데이터를 입력할 때는 랜덤 방식을 사용한다. 즉, Freelist로부터 할당 받은 블록에 정해진 순서 없이 데이터를 입력한다.
- 반면, IOT는 인덱스 구조 테이블이므로 정렬 상태를 유지하며 데이터를 입력한다.

<br/>

- IOT는 인위적으로 클러스터링 팩터를 좋게 만드는 방법 중 하나다. 같은 값을 가진 레코드들이 100% 정렬된 상태로 모여 있으므로 랜덤 액세스가 아닌 시퀀셜 방식으로 데이터를 액세스한다. 이 때문에 BETWEEN이나 부등호 조건으로 넓은 범위를 읽을 때 유리하다.
- 데이터 입력과 조회 패턴이 서로 다른 테이블에도 유용하다. 예를 들어, 어떤 회사에 영업사원이 100명이라고 가정하자. 영업사원들의 일별 실적을 집계하는 테이블이 있는데, 한 블록에 100개 레코드가 담긴다. 그러면 매일 한 블록씩 1년이면 365개 블록이 생긴다.

```
SELECT SUBSTR(일자, 1, 6) 월도
     , SUM(판매금액) 총판매금액, AVG(판매금액) 평균판매금액
FROM   영업실적
WHERE  사번 = 'S1234'
AND    일자 BETWEEN '20180101' AND '20181231'
GROUP BY SUBSTR(일자, 1, 6)
``` 
- 실적등록은 일자별로 진행되지만, 실적조회는 주로 사원별로 이루어진다.
- 위 쿼리를 영업부서에서 가장 많이 수행한다고 가정하자. 이 쿼리에 인덱스를 사용한다면, 사원마다 랜덤 액세스 방식으로 365개 테이블 블록을 읽어야 한다. 클러스터링 팩터가 매우 안 좋으므로 조회 건수만큼 블록 I/O가 발생한다.

```
CREATE TABLE 영업실적 ( 사번 VARCHAR2(5), 일자 VARCHAR2(8), ...
       , CONSTRAINT 영업실적_PK PRIMARY KEY (사번, 일자) ) ORGANIZATION INDEX ;
```
- 이처럼 입력과 조회 패턴이 서로 다를 때, 위와 같이 사번이 첫 번째 정렬 기준이 되도록 IOT를 구성해 주면, (한 블록에 100개 레코드가 담기므로) 네 개 블록만 읽고 처리할 수 있다.


### 3.1.7 클러스터 테이블

#### 인덱스 클러스터 테이블
- 인덱스 클러스터 테이블은 클러스터 키 값이 같은 레코드를 한 블록에 모아서 저장하는 구조다.
- 한 블록에 모두 담을 수 없을 때는 새로운 블록을 할당해서 클러스터 체인으로 연결한다.
- 심지어 여러 테이블 레코드를 같은 블록에 저장할 수도 있는데, 이를 `다중 테이블 클러스터`라고 부른다. 일반 테이블은 하나의 데이터 블록을 여러 테이블이 공유할 수 없음을 상기하자.
- 클러스터형 인덱스는 IOT에 가깝다. 오라클 클러스터는 키 값이 같은 데이터를 같은 공간에 저장해 둘 뿐, IOT나 SQL Server의 클러스터형 인덱스처럼 정렬하지는 않는다.

```
CREATE CLUSTER C_DEPT# ( DEPTNO NUMBER(2) ) INDEX ;
```
- 인덱스 클러스터 테이블을 구성하려면 먼저 위와 같이 클러스터를 생성한다.

```
CREATE INDEX C_DEPT#_IDX ON CLUSTER C_DEPT# ;
```
- 클러스터에 테이블을 담기 전에 위와 같이 클러스터 인덱스를 반드시 정의해야 한다.
- 왜냐하면 클러스터 인덱스는 데이터 검색 용도로 사용할 뿐만 아니라 데이터가 저장될 위치를 찾을 때도 유용하기 때문이다.

```
CREATE TABLE DEPT (
    DEPTNO NUMBER(2) NOT NULL
    , DNAME VARCHAR2(14) NOT NULL
    , LOC VARCHAR2(13) )
CLUSTER C_DEPT#( DEPTNO ) ;
```
- 클러스터 인덱스를 만들었으면 위와 같이 클러스터 테이블을 생성한다.

![그림3-13](https://github.com/user-attachments/assets/462b9ef5-cfa2-4a32-b40f-6d4fb266d600)
- 클러스터 인덱스도 B*Tree 인덱스 구조를 사용하지만, 테이블 레코드를 일일이 가리키지 않고 해당 키 값을 저장하는 첫 번째 데이터 블록을 가리킨다는 점이 다르다.
- 즉, 일반 테이블에 생성한 인덱스 레코드는 테이블 레코드와 1:1 대응 관계를 맺지만, 클러스터 인덱스는 테이블 레코드와 1:M 관계를 갖는다. 따라서 클러스터 인덱스의 키 값은 항상 Unique하다(중복 값이 없다).
- 이런 구조적 특성 때문에 클러스터 인덱스를 스캔하면서 값을 찾을 때는 랜덤 액세스가 (클러스터 체인을 스캔하면서 발생하는 랜덤 액세스는 제외하고) 값 하나당 한 번씩 밖에 발생하지 않는다.
- 클러스터에 도달해서는 시퀀셜 방식으로 스캔하기 때문에 넓은 범위를 읽더라도 비효율이 없다는 게 핵심 원리다.

#### 해시 클러스터 테이블

![그림3-14](https://github.com/user-attachments/assets/4ebbc747-f9cc-43da-a784-c56830148ba2)
- 해시 클러스터는 인덱스를 사용하지 않고 해시 알고리즘을 사용해 클러스터를 찾아간다는 점만 다르다.

```
CREATE CLUSTER C_DEPT# ( DEPTNO NUMBER(2) ) HASHKEYS 4 ;
```
- 해시 클러스터 테이블을 구성하려면 위와 같이 클러스터를 생성한다.

```
CREATE TABLE DEPT (
    DEPTNO NUMBER(2) NOT NULL
    , DNAME VARCHAR2(14) NOT NULL
    , LOC VARCHAR2(13) )
CLUSTER C_DEPT# ( DEPTNO ) ;
```
- 그리고 위와 같이 클러스터 테이블을 생성한다.


## 3.2 부분범위 처리 활용


### 3.2.1 부분범위 처리
- DBMS가 클라이언트에게 데이터를 전송할 때 일정량씩 나누어 전송한다. 전체 결과집합 중 아직 전송하지 않은 분량이 많이 남아있어도 서버 프로세스는 클라이언트로부터 추가 Fetch Call을 받기 전까지 그대로 멈춰 서서 기다린다.

```
private void execute(Connection con) throws Exception {
    Statement stmt = con.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT NAME FROM BIG_TABLE");

    for(int i = 0; i < 100; i++) {
        if(rs.next()) {
            System.out.println("rs.getString(1));
        }
    }

    rs.close();
    stmt.close();
}
```
- 위 Java 메소드에서 호출하는 BIG_TABLE이 1억 건에 이르는 대용량 테이블이어도 실행 결과는 곧바로 출력된다. 이유는, DBMS가 데이터를 모두 읽어 한 번에 전송하지 않고 먼저 읽는 데이터부터 일정량(Array Size)을 전송하고 멈추기 때문이다.
- 데이터를 전송하고 나면 서버 프로세스는 CPU를 OS에 반환하고 대기 큐에서 잠을 잔다. 다음 Fetch Call을 받으면 대기 큐에서 나와 그다음 데이터부터 일정량을 읽어서 전송하고 또다시 잠을잔다.
- 이처럼 전체쿼리 결과집합을 쉼 없이 연속적으로 전송하지 않고 사용자로부터 Fetch Call이 있을 때마다 일정량씩 나누어 전송하는 것을 이른바 `부분범위 처리`라고 한다.
- 데이터를 전송하는 단위인 Array Size는 클라이언트 프로그램에서 설정한다. JAVA에서 Array Size 기본값은 10이며, Statement 객체 setFetchSize 메소드를 통해 설정을 변경할 수 있다.
- Array Size가 10인 상태에서 Java 프로그램이 데이터를 읽어 들이는 메커니즘은 아래와 같다.
    - 1. 최초 rs.next() 호출 시 Fetch Call을 통해 DB 서버로부터 전송받은 데이터 10건을 클라이언트 캐시에 저장한다.
    - 2. 이후 rs.next() 호출할 때는 Fetch Call을 발생시키지 않고 캐시에서 데이터를 읽는다.
    - 3. 캐시에 저장한 데이터를 모두 소진한 상태에서 rs.next() 호출 시 추가 Fetch Call을 통해 10건을 전송받는다.
    - 4. 100건을 다 읽을 때까지 2~3번 과정을 반복한다.
- 100개 레코드를 전송받아 콘솔에 출력(내부적으로 연속해서 10번의 Fetch Call 발생)하고는 곧바로 ResultSet과 Statement 객체를 닫았으므로 위 Java 프로그램은 BIG_TABLE에 데이터가 아무리 많아도 오래 걸릴 이유가 없다.

#### 정렬 조건이 있을 때 부분범위 처리
```
    Statement stmt = con.createStatement();
    ResultSet rs = stmt.executeQuery("SELECT NAME FROM BIG_TABLE ORDER BY CREATED");
```
- 쿼리문에 ORDER BY를 추가하면 DB 서버는 **모든** 데이터를 다 읽어 CREATED 순으로 정렬을 마치고서야 클라이언트에게 데이터 전송을 시작할 수 있다. 부분범위가 아닌 전체범위 처리로 동작한다. Sort Area와 Temp 테이블스페이스까지 이용해 데이터 정렬을 마치고 나면 그때부터 일정량씩 나눠 클라이언트에게 데이터를 전송한다.
- 다행히 CREATED 컬럼이 선두인 인덱스가 있으면, 부분범위 처리가 가능하다. 인덱스는 항상 정렬된 상태를 유지하므로 전체 데이터를 정렬하지 않고도 정렬된 상태의 결과집합을 바로 전송할 수 있기 때문이다.


#### Array Size 조정을 통한 Fetch Call 최소화
- 대량 데이터를 파일로 내려받는 경우에는 어차피 데이터를 모두 전송해야 하므로 가급적 Array Size 값을 크게 설정해야 한다. Array Size를 조정한다고 해서 전송해야 할 총량이 변하진 않지만, Fetch Call 횟수를 그만큼 줄일 수 있다.
- 반대로, 앞쪽 일부 데이터만 Fetch하다가 멈추는 프로그램이라면 Array Size를 작게 설정하는 것이 유리하다. 불필요하게 많은 데이터를 전송하고 버리는 비효율을 줄일 수 있기 때문이다.
- 100개 레코드만 필요한 Java 프로그램에서 Array Size를 1,000으로 설정한다면, 사용하지도 않고 버릴 뒤쪽 900개 레코드를 읽어서 전송하는 과정에 네트워크와 서버, 클라이언트 자원만 낭비하게 된다.


### 3.2.2 부분범위 처리 구현
- 아래 Java 소스는 부분범위 처리를 활용하지 않은 예시다.
```
public class AllRange {
    
    public static void execute(Connection con) throws Exception {
        int arraysize = 10;

        String SQLStmt = "SELECT OBJECT_ID, OBJECT_NAME FROM ALL_OBJECTS";
        Statement stmt = con.createStatement();
        stmt.setFetchSize(arraysize);

        ResultSet rs = stmt.executeQuery(SQLStmt);
        while(rs.next()) {
            System.out.println(rs.getLong(1) + " : " + rs.getString(2));
        }
        rs.close();
        stmt.close();
    }

    public static void main(String[] args) throws Exception {
        Connection con = getConnection();
        execute(con);
        releaseConnection(con);
    }

}
```

- 아래 Java 소스는 부분범위 처리를 활용한 예시다. 출력 레코드 수가 Array Size에 도달하면 멈추었다가 사용자 요청이 있을 때 다시 데이터를 Fetch하는 부분이 있다. 보통은 개발 프레임워크에 미리 구현돼 있는 기능을 활용한다.

```
import java.io.*;
import java.lang.*;
import java.util.*;
import java.net.*;
import java.sql.*;
import oracle.jdbc.driver.*;

public class PartialRange {

    public static int fetch(ResultSet rs, int arraysize) throws Exception {
        int i = 0;
        while(rs.next()) {
            System.out.println(rs.getLong(1) + " : " + rs.getString(2));
            if(++i >= arraysize) return i;
        }
        return i;
    }
    
    public static void execute(Connection con) throws Exception {
        int arraysize = 10;

        String SQLStmt = "SELECT OBJECT_ID, OBJECT_NAME FROM ALL_OBJECTS";
        Statement stmt = con.createStatement();
        stmt.setFetchSize(arraysize);

        ResultSet rs = stmt.executeQuery(SQLStmt);
        while(rs.next()) {
            int r = fetch(rs, arraysize);
            if(r < arraysize) break;
            System.out.println("Enter to Continue ... (Q)uit?");
            
            BufferedReader in = new BufferedReader(new InputStreamReader(System.in));
            String input = in.readLine();
            if(input.equals("Q")) break;
        }
        rs.close();
        stmt.close();
    }

    public static void main(String[] args) throws Exception {
        Connection con = getConnection();
        execute(con);
        releaseConnection(con);
    }

}
```


### 3.2.3 OLTP 환경에서 부분범위 처리에 의한 성능개선 원리
- `OLTP(Online Transaction Processing)` 시스템은 일반적으로 소량 데이터를 읽고 갱신하는 `온라인 트랜잭션`을 처리하는 시스템이다.
- 인덱스를 이용해 수천수만 건을 조회할 경우 만족할만한 성능을 내기 어려울 수 있다. 많은 랜덤 테이블 액세스가 발생하기 때문이다. 우연히 버퍼캐시히트율이 좋다면 빠른 성능을 보일 수도 있지만, 그렇지 않다면 수십 초간 기다려야 할 수도 있다.
- OLTP성 업무에서 쿼리 결과 집합이 아주 많을 때 사용자가 모든 데이터를 일일이 다 확인하지는 않는다. 특정한 정렬 순서로 상위 일부 데이터만 확인한다.
- 주로 목록을 조회하는 경우(은행계좌 입출금 조회, 뉴스 또는 게시판(BBS) 조회 등)이며, 이럴 때 항상 정렬 상태를 유지하는 인덱스를 이용하면, 정렬 작업을 생략하고 앞쪽 일부 데이터를 아주 빠르게 보여줄 수 있다.

```
SELECT 게시글ID, 제목, 작성자, 등록일시
FROM   게시판
WHERE  게시판구분코드 = 'A'
ORDER BY 등록일시 DESC
```
- 위 SQL 쿼리에서 인덱스 선두 컬럼을 `게시판구분코드 + 등록일시` 순으로 구성하지 않으면(게시판구분코드 단일 컬럼으로 구성하거나, 게시판구분코드 바로 뒤에 등록일시가 위치하지 않으면), 소트 연산을 생략할 수 없다.
- 게시판구분코드 = 'A' 조건을 만족하는 모든 레코드를 인덱스에서 읽어야 하고, 그만큼 많은 테이블 랜덤 액세스가 발생한다. 모든 데이터를 다 읽어 등록일시 역순으로 정렬을 마치고서야 출력을 시작하므로 OLTP 환경에서 요구되는 빠른 응답 속도를 내기 어렵다.

```
ID | OPERATION                       | NAME | ROWS  | BYETS | COST
-------------------------------------------------------------------
 0 | SELECT STATEMENT                |      | 40000 | 3515K | 2041
 1 |  SORT ORDER BY                  |      | 40000 | 3515K | 2041
 2 |   TABLE ACCESS BY INDEX ROWID   |      | 40000 | 3515K | 1210
 3 |    INDEX RANGE SCAN             |      | 40000 |       | 96
```
- 위 실행계획은 인덱스로 소트 연산을 생략할 수 없을 때 나타난다.

```
ID | OPERATION                       | NAME       | ROWS | BYETS | COST
-------------------------------------------------------------------
 0 | SELECT STATEMENT                |           | 40000 | 3515K | 1372
 1 |  TABLE ACCESS BY INDEX ROWID    | 게시판     | 40000 | 3515K | 1372
 2 |   INDEX RANGE SCAN DESCENDING   | 게시판_X02 | 40000 |       | 258
```
- 위 실행계획은 인덱스를 `게시판구분코드 + 등록일시`순으로 구성하여 Sort Order by 연산을 생략한 실행계획이다. SQL문에 Order By 절이있음에도 불구하고 Sort Order By 오퍼레이션이 자동으로 제거되었다.


#### 멈출 수 있어야 의미있는 부분범위 처리
- **문제는 앞쪽 일부만 출력하고 멈출 수 있는가이다**. 이것이 부분범위 처리의 핵심이다.
- 토드나 오렌지 같은 쿼리 툴은 이미 그렇게 구현이 되어있다. 클라이언트 프로그램이 DB 서버에 직접 접속하는 2-Tier 환경에서는 그렇게 구현할 수 있었고, 실제로도 그렇게 많이 구현했었다.
- 그런데 클라이언트와 DB 서버 사이에 WAS, AP 서버 등이 존재하는 n-Tier 아키텍처에서는 클라이언트가 특정 DB 커넥션을 독점할 수없다. 단위 작업을 마치면 DB 커넥션을 곧바로 커넥션 풀에 반환해야 하므로 그 전에 SQL 조회 결과를 클라이언트에게 **모두** 전송하고 커서(Cursor)를 닫아야 한다. 따라서 SQL 결과집합을 조금씩 나눠 전송하도록 구현하기 어렵다.


## 3.3 인덱스 스캔 효율화
- IOT, 클러스터, 파티션은 테이블 랜덤 액세스를 최소화하는 데 매우 효과적인 저장구조이지만, 운영 시스템 환경에서 이를 적용하려면 성능 검증을 위해 많은 테스트를 진행해야 하므로 어려움이 따른다.
- 운영 환경에서 가능한 일반적인 튜닝 기법은 인덱스 컬럼 추가다.


### 3.3.1 인덱스 탐색
![그림3-19](https://github.com/user-attachments/assets/3813cf4b-e157-4806-9c36-d34f273d3a29)
- 루트 블록에 (C1, C2) 컬럼이 각각 (A, 3), (B, 3), (C, 2)인 3개 레코드가 있다. 각 레코드는 하위 노드를 가리키는 블록 주소를 갖는다. 자신이 가리키는 주소(화살표)로 찾아간 블록에는 자신의 키 값보다 크거나 같은 값을 갖는 레코드가 저장돼 있음을 의미한다.
- 예를 들어, (B, 3)이가리키는 주소로 찾아간 블록에는 C1 = 'B'이고 C2 = 3인 레코드보다 값이 크거나 같은 레코드(두 컬럼 모두 한 자릿수라고 할 때, C1 || C2 >= 'B3'인 레코드)가 저장돼 있다.
- 루트 블록에는 키 값을 갖지 않는 특별한 레코드가 하나 있다. 가장 왼쪽에 있는 `LMC(Leftmost Child)` 레코드다. LMC는 자식 노드 중 가장 왼쪽 끝에 위치한 블록을 가리킨다.
- LMC가 가리키는 주소로 찾아간 블록에는 **키 값을 가진 첫번째 레코드(위 그림에서는 C1='A' AND C2=3인 레코드)보다 작거나 같은 값**을 갖는 레코드가 저장돼 있다.

```
<조건절 1>
WHERE C1 = 'B'
```
![그림3-20](https://github.com/user-attachments/assets/6101f20f-f0d6-4c59-be17-1a63abfdad74)
- 조건절 1의 스캔 시작점과 끝점은 위 그림과 같다.
- 수직적 탐색을 통해 C1 = 'B'인 첫 번째 레코드를 찾고, 'C'를 만나는 순간 스캔을 멈춘다. 점선 화살표(-->)는 블록 내에서 시작점을 찾는 과정을 표시한 것이다.
- 주의할 점이 있다. 루트 블록 스캔 과정에 C1 = 'B'인 레코드를 찾았을 때 그것이 가리키는 리프 블록 3으로 내려가면 안 된다. 그 직전(C1 = 'A') 레코드가 가리키는 리프 블록 2로 내려가야 한다. C1 = 'B'인 레코드가 가리키는 리프 블록 3으로 내려가도 조건을 만족하는 데이터를 만날 수 있지만, 거기가 스캔 시작점은 아니다.

```
<조건절 2>
WHERE C1 = 'B'
AND   C2 = 3
```
![그림3-21](https://github.com/user-attachments/assets/3bf88cb5-a107-4df9-9f7b-9848f0af2f4c)
- 조건절 2의 스캔 시작점과 끝점은 위 그림과 같다.
- 수직적 탐색을 통해 C1 = 'B'이고 C2 = 3인 첫 번째 레코드를 찾고, C1 = 'B'인 레코드 중에서 C2 = 4인 레코드를 만나는 순간 스캔을 멈춘다. C1과 C2 조건절 모두 스캔 시작과 끝 지점을 결정하는 데 중요한 역할을 했다. 즉, 스캔량을 줄이는 데 역할을 했다.
- 여기서도 루트 블록 스캔 과정에 C1 = 'B'이고 C2 = 3인 레코드를 찾았다고 거기서 가리키는 리프 블록 3으로 내려가선 안 된다. 그 직전 레코드가 가리키는 리프 블록 2로 내려가야 한다.

```
<조건절 3>
WHERE C1 = 'B'
AND   C2 >= 3
```
![그림3-22](https://github.com/user-attachments/assets/8e35df77-b9c3-4686-8910-95c3b4070dbf)
- 조건절 3의 스캔 시작점과 끝점은 위 그림과 같다.
- 수직적 탐색을 통해 C1 = 'B'이고 C2 >= 3인 첫 번째 레코드를 찾고, C1 = 'C'인 레코드를 만날 때까지 스캔하다가 멈춘다.
- C2 >= 3 조건절이 스캔을 멈추는 데는 역할을 전혀 못 하지만 이 조건절로 인해 조건절 1과 스캔 시작점이 달라졌다. 부등호 조건이지만 수직적 탐색 과정에 사용됨으로써 스캔 시작점을 결정하는 데 중요한 역할을 했다. 즉, 스캔량을 줄이는 데 역할을 했다.

```
<조건절 4>
WHERE C1 = 'B'
AND   C2 <= 3
```
![그림3-23](https://github.com/user-attachments/assets/117988e6-50f7-491d-b4c1-788ce09e85cf)
- 조건절 4의 스캔 시작점과 끝점은 위 그림과 같다.
- 수직적 탐색을 통해 C1 = 'B'인 첫 번째 레코드를 찾고, 거기서부터 스캔하다가 C2 > 3인 첫 번째 레코드를 만나는 순간 스캔을 멈춘다.
- C2 <= 3 조건절은 수직적 탐색 과정에 전혀 쓰이질 않았다. 스캔 시작점을 결정하는 데 전혀 역할을 못했지만, 스캔을 멈추는 데는 중요한 역할을 했다. 즉, 스캔량을 줄이는 역할을 했다.

```
<조건절 5>
WHERE C1 = 'B'
AND   C2 BETWEEN 2 AND 3
```
![그림3-24](https://github.com/user-attachments/assets/07e0d34e-e8d1-4713-9631-bcd4b47732db)
- 조건절 5의 스캔 시작점과 끝점은 위 그림과 같다.
- 수직적 탐색을 통해 C1 = 'B'이고 C2 >= 2인 첫 번째 레코드를 찾고, C2 > 3인 첫 번째 레코드를 만나는 순간 스캔을 멈춘다.
- 여기서는 C1과 C2 조건절 모두 스캔 시작과 끝 지점을 결정하는 데 중요한 역할을 했다. 즉, 스캔량을 줄이는 역할을 했다.

```
<조건절 6>
WHERE C1 BETWEEN 'A' AND 'C'
AND   C2 BETWEEN  2  AND  3
```
![그림3-25](https://github.com/user-attachments/assets/39ae8323-dd47-4514-9e6b-4af148316885)
- 조건절 6의 스캔 시작점과 끝점은 위 그림과 같다.
- 수직적 탐색을 통해 C1 >= 'A'이고 C2 >= 2인 첫 번째 레코드에서 스캔을 시작하고, C1 = 'C'이고 C2 = 3인 레코드보다 값이 큰 레코드(두 컬럼 모두 한 자릿수라고 할 때, C1 || C2 > 'C3'인 레코드)를 만나는 순간 스캔을 멈춘다.
- C1 조건절은 스캔 시작과 끝 지점을 결정하는 데 중요한 역할을 했지만, C2는 그렇지 못하다. 맨 앞 C1 = 'A'인 구간과 맨 뒤 C1 = 'C' 구간에서는 어느 정도 역할을 했지만 중간 C1 = 'B' 구간에서는 전혀 역할을 못 했다. 즉, C2는 스캔량을 줄이는 데 거의 역할을 하지 못했다.


### 3.3.2 인덱스 스캔 효율성

![그림3-26](https://github.com/user-attachments/assets/f0a91cee-5588-4e35-b1e2-5d4133546ffb)
- '성능검'으로 시작하는 용어를 검색하고자 할 때 어디서 스캔을 시작하고 어디서 멈출까?
- 위 그림처럼 '성능검사'에서 스캔을 시작한다. 가나다 순으로 정렬돼 있으므로 바로 이 지점으로 찾아갈 수 있다. 가나다 순으로 정렬돼 있으므로 끝까지 안 읽고 멈출 수도 있다. 용어가 '성능계수'인 지점에서 멈추면 된다. '성능검'으로 시작하는 용어가 더 없음을 확인하기 위해 '성능계수'까지 읽은 것이다.
- 2건을 얻기 위해 총 3건을 읽었다.

![그림3-27](https://github.com/user-attachments/assets/6f240aa7-7ac3-4647-bace-19f9f6fe7d53)
- '성능'으로 시작하고 네 번째 문자가 '선'인 용어를 검색해 보자.
- 위 그림처럼 '성능'으로 시작하는 용어를 모두 스캔한다. 결과는 앞의 질문과 같이 2건이지만, 훨씬 더 많은 용어를 스캔해야만 한다.

![그림3-28](https://github.com/user-attachments/assets/1f50f250-7834-4f84-9c22-99cf3c65cf72)
```
WHERE C1 = '성'
AND   C2 = '능'
AND   C3 = '검'
```
- 이번에는 각 문자를 잘라서 테이블 컬럼에 각각 저장하고, C1 + C2 + C3 + C4 순으로 인덱스를 생성해 보자.
- 위 테이블에서 '성능검'으로 시작하는 레코드를 검색할 때는 인덱스 수직적 탐색을 통해 위 그림처럼 '성능검사' 레코드로 찾아간다. 거기서 스캔을 시작해 '성능계수'까지 총 3개 레코드를 스캔하고 멈춘다. 2건을 얻기 위해 3건을 스캔했다.

![그림3-29](https://github.com/user-attachments/assets/004020b2-c3dd-4a7b-95c4-51ff5f80b895)
```
WHERE C1 = '성'
AND   C2 = '능'
AND   C4 = '선'
```
- '성능'으로 시작하고 네 번째 컬럼이 '선'인 레코드를 검색할 때는 '성능'으로 시작하는 레코드를 모두 스캔한다. 결과는 똑같이 2건이지만, 훨씬 더 많은 인덱스 레코드를 스캔해야만 한다.
- 인덱스 스캔을 통해 얻은 결과 건수는 똑같은데 왜 이처럼 인덱스 리프 블록에서 스캔하는 레코드 개수에 차이가 생기는 걸까? 왜 효율성에 차이가 나는 걸까? 구체적으로, 왜 후자는 전자보다 들인 노력에 비해 얻은 결과가 적을까?
- 인덱스 선행 컬럼이 조건절에 없기 때문이다. 바로 위 그림에서는 C4보다 앞선 선행 컬럼 C3가 조건절에 없기 때문이다. 인덱스 선행 컬럼이 조건절에 없거나 '=' 조건이 아니면 인덱스 스캔 과정에 비효율이 발생한다.

#### 인덱스 효율성 측정
- 인덱스 스캔 효율이 좋은지 나쁜지는 어떻게 알 수 있을까? SQL 트레이스를 통해 쉽게 알 수 있다.
```
ROWS   ROW SOURCE OPERATION
------ ---------------------------------------------------------------------------
10     TABLE ACCESS BY INDEX ROWID BIG_TABLE (cr=7471 pr=1466 pw=0 time=22137 us)
10      INDEX RANGE SCAN BIG_TABLE_IDX (cr=7463 pr=1466 pw=0 time=22328 us)
``` 

- 위 트레이스를 분석해 보면, 인덱스를 스캔하고 얻은 레코드가 열 개인데, 그 과정에 7,463개블록(cr=7463)을 읽었다는 사실을 알 수 있다. 인덱스 리프 블록에는 테이블 블록보다 훨씬 더 많은 레코드가 담긴다. 한 블록당 평균 500개 레코드가 담긴다고 가정하면, 3,731,500(=7,473x500)개 레코드를 읽은 셈이다. 그 많은 데이터를 읽고 고작 10개를 얻었다.


### 3.3.3 액세스 조건과 필터 조건
![그림3-30](https://github.com/user-attachments/assets/cfe9d716-7640-4199-9058-969cb8a3e9d4)
- 인덱스를 스캔하는 단계에 처리하는 조건절은 액세스 조건과 필터 조건으로 나뉜다.
- `인덱스 액세스 조건`은 인덱스 스캔 범위를 결정하는 조건절이다. 인덱스 수직적 탐색을 통해 스캔 시작점을 결정하는 데 영향을 미치고, 인덱스 리프 블록을 스캔하다가 어디서 멈출지를 결정하는 데 영향을 미치는 조건절이다.
- `인덱스 필터 조건`은 테이블로 액세스할지를 결정하는 조건절이다.
- 앞서 살펴본 그림3-28 인덱스에서는 C1, C2, C3가 모두 인덱스 액세스 조건이었다. 그림3-29 인덱스에서는 C1, C2가 인덱스 액세스 조건이고, C4는 인덱스 필터 조건이었다.
- 인덱스를 이용하든, 테이블을 Full Scan하든, 테이블 액세스 단계에서 처리되는 조건절은 모두 필터 조건이다.
- `테이블 필터 조건`은 쿼리 수행 다음 단계로 전달하거나 최종 결과집합에 포함할지를 결정한다.

#### 옵티마이저의 비용 계산 원리
```
비용 
= 인덱스 수직적 탐색 비용 + 인덱스 수평적 탐색 비용 + 테이블 랜덤 액세스 비용
= 인덱스 루트와 브랜치 레벨에서 읽는 블록 수 +
  인덱스 리프 블록을 스캔하는 과정에서 읽는 블록 수 +
  테이블 액세스 과정에 읽는 블록 수 
```


### 3.3.4 비교 연산자 종류와 컬럼 순서에 따른 군집성
- 테이블과 달리 인덱스에는 '같은 값'을 갖는 레코드들이 서로 군집해 있다. '같은 값'을 찾을 때 '=' 연산자를 사용하므로 인덱스 컬럼을 앞쪽부터 누락없이 '=' 연산자로 조회하면 조건절을 만족하는 레코드는 모두 모여 있다. 어느 하나를 누락하거나 '=' 조건이 아닌 연산자로 조회하면 조건절을 만족하는 레코드가 서로 흩어진 상태가 된다.
- 아래 조건절 1과 같이 인덱스 구성 컬럼(C1, C2, C3, C4)을 모두 '=' 조건으로 비교할 때는 만족하는 레코드들이 모두 연속해서 모여 있다.
```
<조건절 1>
WHERE C1 = 1
AND   C2 = 'A'
AND   C3 = '나'
AND   C4 = 'a'
```

- 아래 조건절 2처럼 선행 컬럼은 모두 '='이고 맨 마지막 컬럼만 범위검색 조건(부등호, BETWEEN, LIKE)일 때도 조건을 만족하는 레코드가 서로 모여 있다.
```
<조건절 2>
WHERE C1 = 1
AND   C2 = 'A'
AND   C3 = '나'
AND   C4 >= 'a'
```

- 만약 맨 마지막 컬럼이 아닌 중간 컬럼이 범위검색 조건일 때는 어떻게 될까? 아래 조건절 3과 같이 세 번째 컬럼 C3가 범위검색 조건인 경우는 C1부터 C3까지세 조건을 만족하는 인덱스 레코드는 서로 모여 있지만, C4 조건까지 만족하는 레코드는 흩어지게 된다.
```
<조건절 3>
WHERE C1 = 1
AND   C2 = 'A'
AND   C3 BETWEEN '가' AND '다'
AND   C4 = 'a'
```

- 아래 조건절 4와 같이 두 번째 컬럼 C2가 범위검색 조건인 경우는 C1부터 C2까지 두 조건을 만족하는 레코드는 서로 모여 있지만, C3와 C4 조건까지 만족하는 레코드는 흩어지게 된다.
```
<조건절 4>
WHERE C1 = 1
AND C2 <= 'B'
AND C3 = '나'
AND C4 BETWEEN 'a' AND 'b'
```

- 여기서 한 가지 규칙을 발견할 수 있다. 선행 컬럼이 모두 '=' 조건인 상태에서 `첫 번째 나타나는 범위검색 조건까지만 만족하는 인덱스 레코드는 모두 연속해서 모여 있지만, 그 이하 조건까지 만족하는 레코드는 비교 연산자 종류에 상관없이 흩어진다`는 규칙이다.
- 만약 아래 조건절 5와 같이 선두 C1 컬럼이 범위검색 조건이면 C1 조건을 만족하는 레코드는 서로 모여 있고, 나머지 조건까지 만족하는 레코드는 비교 연산자 종류에 상관없이 흩어지게 된다.
```
<조건절 5>
WHERE C1 BETWEEN 1 AND 3
AND   C2 = 'A'
AND   C3 = '나'
AND   C4 = 'a'
```

- 앞서 3.3.3에서 인덱스 스캔 범위를 결정하는 조건절이 인덱스 액세스 조건이라고 설명한 것을 상기하자. 선행 컬럼이 모두 '=' 조건인 상태에서 첫 번째 나타나는 범위검색 조건이 인덱스 스캔 범위를 결정한다. 조건절 5처럼 가장 선두 컬럼이 범위검색 조건이면, 그 조건이 스캔 범위를 결정한다. 따라서 이들 조건이 인덱스 액세스 조건이다. 나머지 인덱스 컬럼 조건은 모두 인덱스 필터 조건이다.

![표3-1](https://github.com/user-attachments/assets/d2f11aec-d16c-4150-afcf-be6f6d9b1f84)

#### 범위검색 조건 맨 처음과 마지막 구간에서의 액세스 조건
- 사실 조건절 5에서 C2, C3, C4도 인덱스 스캔량을 줄이는 데 어느 정도 역할을 한다. C1 = 1인 구간과 C1 = 3인 구간에서 그렇다. 아래 조건을 만족하는 첫 번째 레코드를 찾아 수직적 탐색하므로 C1 = 1 구간에서 스캔 범위를 줄이는 역할을 한다.
```
WHERE C1 >= 1
AND   C2 = 'A'
AND   C3 = '나'
AND   C4 = 'a'
```

- 아래 조건보다 큰 값을 만나는 순간 멈추므로 C1 = 3 구간에서도 스캔 범위를 줄이는 역할을 한다.
```
WHERE C1 <= 3
AND   C2 = 'A'
AND   C3 = '나'
AND   C4 = 'a'
```

- 마찬가지로, 조건절3과 4의 필터 조건도 범위검색 조건 맨 처음과 마지막 구간에서는 스캔량 줄이는 데 역할을 한다. 하지만, 대개 무시할만한 수준이다.
- 오라클은 실행계획 하단에 아래와 같이 액세스 조건과 필터 조건을 정리해서 보여주는데, 조건절 5를 테스트해 보면, C2, C3, C4 컬럼이 액세스 조건에 포함되는 이유가 바로 여기에 있다.
```
Predicate information (indentified by opreation id) :
-----------------------------------------------------------------------
2 - access("C1">=1 AND "C2"='A' AND "C3"='나' AND "C4"='a' AND "C1"<=3)
2 - filter("C2"='A' AND "C3"='나' AND "C4"='a')
```

- 결국, 아래 몇 가지 케이스를 제외하면, `인덱스 컬럼에 대한 조건절은 모두 액세스 조건에 표시`된다. 첫 번째 나타나는 범위검색 조건 이후 조건절 컬럼은 스캔 범위를 줄이는 데 큰 역할을 못 하는데도 말이다.
    - 좌변 컬럼을 가공한 조건절
    - 왼쪽 '%' 또는 양쪽 '%' 기호를 사용한 LIKE 조건절
    - 같은 컬럼에 대한 조건절이 두 개 이상일 때, 인덱스 액세스 조건으로 선택되지 못한 조건절
    - OR Expansion 또는 INLIST ITERATOR로 선택되지 못한 OR 또는 IN 조건절
- 액세스 조건과 필터 조건을 실행계획에 표시된 대로 이해하면 이 둘을 구분할 이유가 없어진다. 첫 번째 나타나는 범위검색 조건까지가 인덱스 액세스 조건이고, 나머지는 필터 조건이라고 이해하는 것이 쉽다.


### 3.3.5 인덱스 선행 컬럼이 등치(=) 조건이 아닐 때 생기는 비효율
- 인덱스 스캔 효율성은 인덱스 컬럼을 조건절에 모두 등치(=) 조건으로 사용할 때 가장 좋다.
- 리프 블록을 스캔하면서 읽은 레코드는 하나도 걸러지지 않고 모두 테이블 액세스로 이어지므로 인덱스 스캔 단계에서의 비효율은 전혀 없다.
- 인덱스 컬럼 중 일부가 조건절에 없거나 등치 조건이 아니더라도, 그것이 뒤쪽 컬럼일 때는 비효율이 없다. 인덱스를 `아파트시세코드 + 평형 + 평형타입 + 인터넷매물` 순으로 구성했을 때 조건절이 아래와 같은 경우를 말한다. 아래 조건절은 모두 인덱스 액세스 조건으로 사용된다.
```
WHERE 아파트시세코드 = :a
WHERE 아파트시세코드 = :a AND 평형 = :b
WHERE 아파트시세코드 = :a AND 평형 = :b AND 평형타입 = :c
WHERE 아파트시세코드 = :a AND 평형 = :b AND 평형타입 BETWEEN :c AND :d
```

- 반면, 인덱스 선행 컬럼이 조건절에 없거나 부등호, BETWEEN, LIKE 같은 범위검색 조건이면, 인덱스를 스캔하는 단계에서 비효율이 생긴다. 예를 들어, 인덱스를 `아파트시세코드 + 평형 + 평형타입 + 인터넷매물` 순으로 구성한 상황에서 아래 SQL을 수행하는 경우를 살펴보자.
```
SELECT 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
FROM   매물아파트매매
WHERE  아파트시세코드 = 'A01011350900056'
AND    평형 = '59'
AND    평형타입 = 'A'
AND    인터넷매물 BETWEEN '1' AND '3'
ORDER BY 입력일 DESC
```
![그림3-32](https://github.com/user-attachments/assets/075a9076-38d4-4cf1-8c6a-b6222bfaae7d)

- 인터넷매물이 BETWEEN 조건이지만 선행 컬럼들(아파트시세코드, 평형, 평형타입)이 모두 '=' 조건이기 때문에 전혀 비효율 없이 조건을 만족하는 세 건을 빠르게 찾았다. 비효율이 전혀 없다는 것을 세 건을 찾기 위해 단 네 건만 스캔했음을 의미한다. 맨 마지막 스캔은 조건을 만족하는 레코드가 더 없음을 확인하기 위한 one-plus 스캔이므로 불가피하다.
- 인덱스 선행 컬럼이 모두 '=' 조건일 때 필요한 범위만 스캔하고 멈출 수 있는 것은, 조건을 만족하는 레코드가 모두 한데 모여 있기 때문이다.

![그림3-33](https://github.com/user-attachments/assets/a6cd5ef6-9265-4175-939b-120718eb4b57)
- 인덱스 구성을 `인터넷매물 + 아파트시세코드 + 평형 + 평형타입` 순으로 바꾼 후 SQL을 수행하면 인덱스 스캔 범위가 넓어진다.
- 인덱스 선두 컬럼인 인터넷매물에 BETWEEN 연산자를 사용하면 나머지 조건(아파트시세코드, 평형, 평형타입)을 만족하는 레코드들이 인터넷매물 값(0, 1, 2, 3)별로 뿔뿔이 흩어져 있게 된다. 따라서 조건을 만족하지 않는 레코드까지 스캔하고서 버리는 비효율이 생긴다.
- 다행스러운 것은 인터넷매물 BETWEEN 조건절 시작 값인 '1' 구간에서는 전체를 다 읽지 않고 아래 조건을 만족하는 첫 번째 레코드부터 읽기 시작한다.
```
WHERE 인터넷매물 = '1'
AND   아파트시세코드 = 'A01011350900056'
AND   평형 = '59'
AND   평형타입 = 'A'
```

- 인터넷매물 BETWEEN 조건절 마지막 값인 '3' 구간에서도 전체를 다 읽지 않고 아래 조건절보다 큰 값을 만나는 순간 스캔을 멈춘다.
```
WHERE 인터넷매물 = '3'
AND   아파트시세코드 = 'A01011350900056'
AND   평형 = '59'
AND   평형타입 = 'A'
```
- 하지만, 인터넷매물 BETWEEN 조건절 중간에 걸친 값 '2' 구간에서는 전체 레코드를 다 읽어야만 한다.


### 3.3.6 BETWEEN을 IN-List로 전환
- 범위검색 컬럼이 맨 뒤로 가도록 인덱스를 `아파트시세코드 + 평형 + 평형타입 + 인터넷매물` 순으로 변경하면 좋겠지만 운영 시스템에서 인덱스 구성을 바꾸기는 쉽지 않다. 이럴 때 BETWEEN 조건을 아래와 같이 IN-List로 바꿔주면 큰 효과를 얻는 경우가 있다.
```
SELECT 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
FROM   매물아파트매매
WHERE  인터넷매물 IN ('1', '2', '3')
AND    아파트시세코드 = 'A01011350900056'
AND    평형 = '59'
AND    평형타입 = 'A'
ORDER BY 입력일 DESC
```

![그림3-34](https://github.com/user-attachments/assets/ca1185c3-2d3c-499f-ac87-e7dadd212c21)
- BETWEEN 조건을 IN-List로 바꾸면 인덱스 수직적 탐색이 세 번 발생한다.
- dbms_xplan.display_cursor 함수를 이용해 Row Source별 수행 통계를 출력해보면 Index Range Scan 단계의 Starts 항목이 3으로 나타난다. 이를 통해 인덱스를 세 번 탐색한다는 사실을 확인할 수 있다.
- 인덱스를 세 번 탐색한다는 것은 SQL을 아래와 같이 작성한 것과 같다. 모든 컬럼이 '=' 조건인 것에 주목하자.
```
SELECT 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
FROM   매물아파트매매
WHERE  인터넷매물 = '1'
AND    아파트시세코드 = 'A01011350900056'
AND    평형 = '59'
AND    평형타입 = 'A'
UNION ALL
SELECT 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
FROM   매물아파트매매
WHERE  인터넷매물 = '2'
AND    아파트시세코드 = 'A01011350900056'
AND    평형 = '59'
AND    평형타입 = 'A'
UNION ALL
SELECT 해당층, 평당가, 입력일, 해당동, 매물구분, 연사용일수, 중개업소코드
FROM   매물아파트매매
WHERE  인터넷매물 = '3'
AND    아파트시세코드 = 'A01011350900056'
AND    평형 = '59'
AND    평형타입 = 'A'
ORDER BY 입력일 DESC
```
- IN-List 개수만큼 UNION ALL 브랜치가 생성되고 각 브랜치마다 모든 컬럼을 '=' 조건으로 검색하므로 앞서 선두 컬럼에 BETWEEN을 사용할 때와 같은 비효율이 사라진다.
- IN-List 항목 개수가 늘어날 수 있다면(예를 들어, 인터넷 매물에 '1'과 '3' 사이에 다른 값 추가), BETWEEN을 IN-List로 전환하는 방식은 사용하기 곤란하다. 그럴 때는 아래처럼 NL 방식의 조인문이나 서브쿼리로 구현하면 된다. 물론 IN-List 값들을 코드 테이블로 관리하고 있을 때 가능한 방식이다. 인터넷매물을 '=' 조건으로 조인하고 있다는 데 주목하자.
```
SELECT /*+ ORDERED USE_NL(B) */ B.해당층, B.평당가, B.입력일
       , B.해당동, B.매물구분, B.연사용일수, B.중개업소코드
FROM   통합코드 A, 매물아파트매매 B
WHERE  A.코드구분 = 'CD064' -- 인터넷매물구분
AND    A.코드 BETWEEN '1' AND '3'
AND    B.인터넷매물 = A.코드
AND    B.아파트시세코드 = 'A01011350900056'
AND    B.평형 = '59'
AND    B.평형타입 = 'A'
ORDER BY B.입력일 DESC
```

#### BETWEEN 조건을 IN-List로 전환할 때 주의 사항
- BETWEEN 조건을 IN-List 조건으로 전환할 때 주의할 점은, IN-List 개수가 많지 않아야 한다는 것이다.
- IN-List 개수가 많으면 수직적 탐색이 많이 발생한다. 그러면 BETWEEN 조건 때문에 리프 블록을 많이 스캔하는 비효율보다 IN-List 개수만큼 브랜치 블록을 반복 탐색하는 비효율이 더 클 수 있다. 루트에서 브랜치 블록까지 Depth가 깊을 때 특히 그렇다.

![그림3-36](https://github.com/user-attachments/assets/22fe8722-db16-4f58-af19-261dec96522b)
- 인덱스 스캔 과정에 선택되는 레코드들이 서로 멀리 떨어져 있을 때만 유용하다. 아래 조건절로 말하면 `고객등급 + 고객번호` 순으로 구성한 인덱스에서 고객번호 = 123 조건을 만족하는 레코드가 서로 멀리 떨어져 있을 때만 BETWEEN 조건을 IN-List로 전환하는 기법이 유용하다.
```
WHERE 고객등급 BETWEEN 'C' AND 'D'
AND   고객번호 = 123
```

![그림3-37](https://github.com/user-attachments/assets/207672c4-4777-47ca-831f-84388abf2636)
- 고객번호 = 123 조건을 만족하는 레코드가 두 건밖에 없다고 가정하자. 그런데 인덱스 선두 컬럼인 고객등급 조건절이 BETWEEN이어서 고객번호 = 123 조건을 만족하는 레코드가 서로 멀리 떨어져 있다. 이 두 건을 찾으려면 인덱스 리프 블록을 많이 스캔해야 한다. 이럴 때 BETWEEN을 IN-List로 변환하면 효과가 크다.
- 조건을 만족하는 두 레코드가 서로 가까이 있으면 BETWEEN을 IN-List로 변환할 때 효과가 전혀 없거나 수직적 탐색 때문에 오히려 블록 I/O가 더 많이 발생한다.
- 정리하면, BETWEEN 조건 때문에 인덱스를 비효율적으로 스캔하더라도 블록 I/O 측면에서는 대개 소량에 그치는 경우가 많다. 인덱스 리프 블록에는 테이블 블록과 달리 매우 많은(8KB 블록 기준으로 대략 수백 개) 레코드가 담기기 때문이다.
- 게다가 IN-List 개수가 많으면 수직적 탐색 과정에서 이미 많은 블록을 읽게 된다. 데이터 분포나 수직적 탐색 비용을 따져보지도 않고 BETWEEN을 IN-List로 변환하는 실수를 범하지 않아야 한다.


### 3.3.7 Index Skip Scan 활용
- BETWEEN 조건을 IN-List 조건으로 변환하면 도움이 되는 상황에서 굳이 조건절을 바꾸지 않고도 같은 효과를 낼 방법이 있다. Index Skip Scan을 활용하는것이다.

```
CREATE TABLE 월별고객별판매집계
AS
SELECT ROWNUM 고객번호
       , '2018' || LPAD(CEIL(ROWNUM/100000), 2, '0') 판매월
       , DECODE(MOD(ROWNUM, 12), 1, 'A', 'B') 판매구분
       , ROUND(DBMS_RANDOM.VALUE(1000, 100000), -2) 판매금액
FROM   DUAL
CONNECT BY LEVEL <= 1200000 ;
```
- 위 테이블에 2018년 1월부터 12월까지 월별로 10만 개(총 120만 개) 판매데이터가 입력되도록 했다. 판매구분 값별로는 'A'가 10만 개, 'B'가 110만 개다. 이 테이블을 이용해 아래와 같은 COUNT 쿼리를 수행하려고 한다.
```
SELECT COUNT(*)
FROM   월별고객별판매집계 T
WHERE  판매구분 = 'A'
AND    판매월 BETWEEN '201801' AND '201812'
```

- 이 쿼리를 최적으로 수행하려면 '=' 조건인 판매구분이 선두컬럼에 위치하도록 아래와 같이 인덱스를 구성해야 한다.
```
CREATE INDEX 월별고객별판매집계_IDX1 ON 월별고객별판매집계(판매구분, 판매월);
```

- 아래는 IDX1 인덱스를 사용할 때의 트레이스 결과로서, 인덱스를 스캔하면서 281개의 블록 I/O가 발생한 것을 볼 수 있다. 테이블 액세스는 전혀 발생하지 않는다.
```
ROWS   ROW SOURCE OPERATION
------ ------------------------------------------------------------------
1      SORT AGGREGATE (cr=281 pr=0 pw=0 time=47753 us)
100000  INDEX RANGE SCAN 월별고객별판매집계_IDX1 (cr=2851 pr=0 pw=0 time=...)
```

- 이번에는 BETWEEN 조건의 판매월 컬럼이 선두인 아래 인덱스를 사용하는 경우를 보자.
```
CREATE INDEX 월별고객별판매집계_IDX1 ON 월별고객별판매집계(판매월, 판매구분);
```

- 판매구분 = 'A'인 레코드는 2018년 1월부터 12월까지 각 판매월 앞쪽에 위치하며, 전체에서 차지하는 비중이 8.3%(=10/120)에 불과하므로 서로 멀리 떨어지게 된다.

![그림3-38](https://github.com/user-attachments/assets/ed04439a-bfab-426d-ab29-4f1b37c1e6a7)

- 아래는 방금 생성한 IDX2 인덱스를 사용할 때의 트레이스 결과로서, 인덱스를 스캔하면서 3,090개 블록 I/O가 발생했다.
```
ROWS   ROW SOURCE OPERATION
------ ------------------------------------------------------------------
1      SORT AGGREGATE (cr=3090 pr=0 pw=0 time=206430 us)
100000  INDEX RANGE SCAN 월별고객별판매집계_IDX1 (cr=3090 pr=0 pw=0 time=...)
```

- 테이블을 전혀 방문하지 않았는데도 I/O가 많이 발생한 이유는, 인덱스 선두 컬럼이 BETWEEN 조건이어서 판매구분이 'B'인 레코드까지 모두 스캔하고서 버렸기 때문이다.
- 앞서 살펴본 튜닝 방식을 적용해 BETWEEN 조건을 IN-List로 전환하고 다시 실행해 보았다.
```
SELECT /*+ INDEX(T 월별고객별판매집계_IDX2) */ COUNT(*)
FROM   월별고객별판매집계 T
WHERE  판매구분 = 'A'
AND    판매월 IN ( '201801', '201802', '201803', '201804', 201805', '201806'
                 , '201807', '201808', '201809', '201810', '201811', 201812' )

ROWS   ROW SOURCE OPERATION
------ ------------------------------------------------------------------
1      SORT AGGREGATE (cr=314 pr=0 pw=0 time=31527 us)
100000  INDEX ITERATOR (cr=314 pr=0 pw=0 time=900030 us)
100000   INDEX RANGE SCAN 월별고객별판매집계_IDX2 (cr=314 pr=0 pw=0 time=...)
```

- 3,090개이던 블록 I/O 개수가 314개로 감소하였다. 인덱스 브랜치 블록을 열두 번 반복 탐색했지만, 리프 블록을 스캔할 때의 비효율을 제거함으로써 성능이 열 배 좋아졌다.
- 마지막으로 Index Skip Scan으로 유도해 보았다.
```
SELECT /*+ INDEX_SS(T 월별고객별판매집계_IDX2) */ COUNT(*)
FROM   월별고객별판매집계 T
WHERE  판매구분 = 'A'
AND    판매월 BETWEEN '201801' AND '201812'

ROWS   ROW SOURCE OPERATION
------ ------------------------------------------------------------------
1      SORT AGGREGATE (cr=300 pr=0 pw=0 time=94282 us)
100000   INDEX SKIP SCAN 월별고객별판매집계_IDX2 (cr=300 pr=0 pw=0 time=500073us)
```
- 인덱스 선두 컬럼이 BETWEEN 조건인데도 큰 비효율 없이 단 300 블록만 읽고 일을 마쳤다. 4가지 테스트 결과를 살펴보면, Index Skip Scan이 IN-List보다 오히려 낫고 `판매구분 + 판매월` 순으로 구성한 IDX1 인덱스를 사용할 때와 비교해서도 큰 차이가 없다.

![표3-2](https://github.com/user-attachments/assets/55647eba-862f-4af2-899c-19b207bc51d6)

- 선두 컬럼이 BETWEEN이어서 나머지 검색 조건을 만족하는 데이터들이 서로 멀리 떨어져 있을 때, Index Skip Scan이 효과적이다.